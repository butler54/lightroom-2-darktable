{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "235fac1d-90cd-4733-b1b3-285c6127beae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import ray\n",
    "import pathlib\n",
    "import sqlite3\n",
    "import tqdm\n",
    "import modin\n",
    "\n",
    "import modin.pandas as pd\n",
    "\n",
    "from rich import print as rprint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "525e6659-ed0f-4ab5-a0bf-d4912d5e1e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = pathlib.Path('/Volumes/photos-new')\n",
    "\n",
    "old_lrcat_dir = base_directory / \"OLD_LR\" / \"lightroom-catalog\" \n",
    "old_lrcat = old_lrcat_dir / \"catalog-2-v13.lrcat\"\n",
    "\n",
    "new_lrcat_dir = base_directory / \"Lightroom\" \n",
    "new_lrcat = new_lrcat_dir / \"Lightroom Catalog-v13-3.lrcat\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2acd0f4-2174-46ab-96ef-016c70a9f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_tables(lrcat: pathlib.Path):\n",
    "    conn = sqlite3.connect(lrcat)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Execute the query to get all table names\n",
    "    cursor.execute(\"SELECT * FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    tnames = []\n",
    "    for table in tables:\n",
    "        tnames.append(table[1])\n",
    "    conn.close()\n",
    "    return tnames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9edf2467-8104-48b0-b40f-40ec04e6aeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_rows(lrcat, tables):\n",
    "    conn = sqlite3.connect(lrcat)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    for table in tables:\n",
    "        cursor.execute(f\"SELECT COUNT(*) FROM {table};\")\n",
    "        rows = cursor.fetchall()\n",
    "        print(f'{table}: {rows}')\n",
    "    conn.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b27f07e6-11b6-4994-8df5-db2ea2b8eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ray.is_initialized():\n",
    "    ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e58e529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_con():\n",
    "    return sqlite3.connect(old_lrcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f20c9c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_sql in module modin.pandas.io:\n",
      "\n",
      "read_sql(sql, con, index_col=None, coerce_float=True, params=None, parse_dates=None, columns=None, chunksize=None, dtype_backend: 'Union[DtypeBackend, NoDefault]' = <no_default>, dtype=None) -> 'DataFrame | Iterator[DataFrame]'\n",
      "    Read SQL query or database table into a DataFrame.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    See pandas API documentation for `pandas.read_sql <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.read_sql.html>`_ for more.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.read_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e126d4ff-9711-4bc1-97b2-496626fd9bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Defaulting to pandas implementation.\n",
      "Reason: To use the parallel implementation of `read_sql`, pass either a SQLAlchemy connectable, the SQL connection string, or a ModinDatabaseConnection with the arguments required to make a connection, instead of <class 'sqlite3.Connection'>. For documentation on the ModinDatabaseConnection, see https://modin.readthedocs.io/en/latest/supported_apis/io_supported.html#connecting-to-a-database-for-read-sql\n",
      "UserWarning: Defaulting to pandas implementation.\n",
      "Reason: To use the parallel implementation of `read_sql`, pass either a SQLAlchemy connectable, the SQL connection string, or a ModinDatabaseConnection with the arguments required to make a connection, instead of <class 'sqlite3.Connection'>. For documentation on the ModinDatabaseConnection, see https://modin.readthedocs.io/en/latest/supported_apis/io_supported.html#connecting-to-a-database-for-read-sql\n",
      "UserWarning: Defaulting to pandas implementation.\n",
      "Reason: To use the parallel implementation of `read_sql`, pass either a SQLAlchemy connectable, the SQL connection string, or a ModinDatabaseConnection with the arguments required to make a connection, instead of <class 'sqlite3.Connection'>. For documentation on the ModinDatabaseConnection, see https://modin.readthedocs.io/en/latest/supported_apis/io_supported.html#connecting-to-a-database-for-read-sql\n",
      "UserWarning: Defaulting to pandas implementation.\n",
      "Reason: To use the parallel implementation of `read_sql`, pass either a SQLAlchemy connectable, the SQL connection string, or a ModinDatabaseConnection with the arguments required to make a connection, instead of <class 'sqlite3.Connection'>. For documentation on the ModinDatabaseConnection, see https://modin.readthedocs.io/en/latest/supported_apis/io_supported.html#connecting-to-a-database-for-read-sql\n",
      "UserWarning: Defaulting to pandas implementation.\n",
      "Reason: To use the parallel implementation of `read_sql`, pass either a SQLAlchemy connectable, the SQL connection string, or a ModinDatabaseConnection with the arguments required to make a connection, instead of <class 'sqlite3.Connection'>. For documentation on the ModinDatabaseConnection, see https://modin.readthedocs.io/en/latest/supported_apis/io_supported.html#connecting-to-a-database-for-read-sql\n",
      "UserWarning: Defaulting to pandas implementation.\n",
      "Reason: To use the parallel implementation of `read_sql`, pass either a SQLAlchemy connectable, the SQL connection string, or a ModinDatabaseConnection with the arguments required to make a connection, instead of <class 'sqlite3.Connection'>. For documentation on the ModinDatabaseConnection, see https://modin.readthedocs.io/en/latest/supported_apis/io_supported.html#connecting-to-a-database-for-read-sql\n",
      "UserWarning: Defaulting to pandas implementation.\n",
      "Reason: To use the parallel implementation of `read_sql`, pass either a SQLAlchemy connectable, the SQL connection string, or a ModinDatabaseConnection with the arguments required to make a connection, instead of <class 'sqlite3.Connection'>. For documentation on the ModinDatabaseConnection, see https://modin.readthedocs.io/en/latest/supported_apis/io_supported.html#connecting-to-a-database-for-read-sql\n"
     ]
    }
   ],
   "source": [
    "#images = pd.read_sql_table(\"Adobe_images\", sqlite3.connect(old_lrcat))\n",
    "connection = sqlite3.connect(old_lrcat)\n",
    "images = pd.read_sql(\"SELECT * from Adobe_images\", connection).drop(columns=['id_global'])\n",
    "library_file = pd.read_sql(\"SELECT * from AgLibraryFile\", connection).drop(columns=['id_global'])\n",
    "library_folder = pd.read_sql(\"SELECT * from AgLibraryFolder\", connection).drop(columns=['id_global'])\n",
    "library_root_folder = pd.read_sql(\"SELECT * from AgLibraryRootFolder\", connection).drop(columns=['id_global'])\n",
    "harvested_exifdata = pd.read_sql(\"SELECT * from AgHarvestedExifMetaData\", connection)\n",
    "exif_camera_model =pd.read_sql(\"SELECT * from AgInternedExifCameraModel\", connection)\n",
    "exif_lens =pd.read_sql(\"SELECT * from AgInternedExifLens\", connection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac61b0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DataFrame in module modin.pandas.dataframe object:\n",
      "\n",
      "class DataFrame(modin.pandas.base.BasePandasDataset)\n",
      " |  DataFrame(data=None, index=None, columns=None, dtype=None, copy=None, query_compiler: 'BaseQueryCompiler' = None) -> 'None'\n",
      " |\n",
      " |  Modin distributed representation of ``pandas.DataFrame``.\n",
      " |\n",
      " |  Internally, the data can be divided into partitions along both columns and rows\n",
      " |  in order to parallelize computations and utilize the user's hardware as much as possible.\n",
      " |\n",
      " |  Inherit common for ``DataFrame``-s and ``Series`` functionality from the\n",
      " |  `BasePandasDataset` class.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  data : DataFrame, Series, pandas.DataFrame, ndarray, Iterable or dict, optional\n",
      " |      Dict can contain ``Series``, arrays, constants, dataclass or list-like objects.\n",
      " |      If data is a dict, column order follows insertion-order.\n",
      " |  index : Index or array-like, optional\n",
      " |      Index to use for resulting frame. Will default to ``RangeIndex`` if no\n",
      " |      indexing information part of input data and no index provided.\n",
      " |  columns : Index or array-like, optional\n",
      " |      Column labels to use for resulting frame. Will default to\n",
      " |      ``RangeIndex`` if no column labels are provided.\n",
      " |  dtype : str, np.dtype, or pandas.ExtensionDtype, optional\n",
      " |      Data type to force. Only a single dtype is allowed. If None, infer.\n",
      " |  copy : bool, default: False\n",
      " |      Copy data from inputs. Only affects ``pandas.DataFrame`` / 2d ndarray input.\n",
      " |  query_compiler : BaseQueryCompiler, optional\n",
      " |      A query compiler object to create the ``DataFrame`` from.\n",
      " |\n",
      " |  Notes\n",
      " |  -----\n",
      " |  See pandas API documentation for `pandas.DataFrame <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.html>`_ for more.\n",
      " |  ``DataFrame`` can be created either from passed `data` or `query_compiler`. If both\n",
      " |  parameters are provided, data source will be prioritized in the next order:\n",
      " |\n",
      " |  1) Modin ``DataFrame`` or ``Series`` passed with `data` parameter.\n",
      " |  2) Query compiler from the `query_compiler` parameter.\n",
      " |  3) Various pandas/NumPy/Python data structures passed with `data` parameter.\n",
      " |\n",
      " |  The last option is less desirable since import of such data structures is very\n",
      " |  inefficient, please use previously created Modin structures from the fist two\n",
      " |  options or import data using highly efficient Modin IO tools (for example\n",
      " |  ``pd.read_csv``).\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      DataFrame\n",
      " |      modin.pandas.base.BasePandasDataset\n",
      " |      modin.logging.class_logger.ClassLogger\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __add__ = add(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  __contains__(self, key) -> 'bool'\n",
      " |      Check if `key` in the ``DataFrame.columns``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : hashable\n",
      " |          Key to check the presence in the columns.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |\n",
      " |  __dataframe__(self, nan_as_null: 'bool' = False, allow_copy: 'bool' = True)\n",
      " |      Get a Modin DataFrame that implements the dataframe exchange protocol.\n",
      " |\n",
      " |      See more about the protocol in https://data-apis.org/dataframe-protocol/latest/index.html.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      nan_as_null : bool, default: False\n",
      " |          A keyword intended for the consumer to tell the producer\n",
      " |          to overwrite null values in the data with ``NaN`` (or ``NaT``).\n",
      " |          This currently has no effect; once support for nullable extension\n",
      " |          dtypes is added, this value should be propagated to columns.\n",
      " |      allow_copy : bool, default: True\n",
      " |          A keyword that defines whether or not the library is allowed\n",
      " |          to make a copy of the data. For example, copying data would be necessary\n",
      " |          if a library supports strided buffers, given that this protocol\n",
      " |          specifies contiguous buffers. Currently, if the flag is set to ``False``\n",
      " |          and a copy is needed, a ``RuntimeError`` will be raised.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      ProtocolDataframe\n",
      " |          A dataframe object following the dataframe protocol specification.\n",
      " |\n",
      " |  __dataframe_consortium_standard__(self, *, api_version: 'str | None' = None)\n",
      " |      Provide entry point to the Consortium DataFrame Standard API.\n",
      " |\n",
      " |      This is developed and maintained outside of Modin.\n",
      " |      Please report any issues to https://github.com/data-apis/dataframe-api-compat.\n",
      " |\n",
      " |  __delitem__(self, key) -> 'None'\n",
      " |      Delete item identified by `key` label.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : hashable\n",
      " |          Key to delete.\n",
      " |\n",
      " |  __divmod__(self, right) -> 'tuple[DataFrame, DataFrame]'\n",
      " |      Return integer division and modulo of Series and `right` (binary operator `divmod`).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      right : Series or scalar value\n",
      " |          The second operand to perform computation.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      tuple of two DataFrames\n",
      " |\n",
      " |  __floordiv__ = floordiv(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  __getattr__(self, key) -> 'Any'\n",
      " |      Return item identified by `key`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : hashable\n",
      " |          Key to get.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Any\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      First try to use `__getattribute__` method. If it fails\n",
      " |      try to get `key` from ``DataFrame`` fields.\n",
      " |\n",
      " |  __iadd__ = add(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  __ifloordiv__ = floordiv(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  __imod__ = mod(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  __imul__ = mul(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  __init__(self, data=None, index=None, columns=None, dtype=None, copy=None, query_compiler: 'BaseQueryCompiler' = None) -> 'None'\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  __ipow__ = pow(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  __isub__ = sub(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  __iter__(self) -> 'Iterable[Hashable]'\n",
      " |      Iterate over info axis.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterable\n",
      " |          Iterator of the columns names.\n",
      " |\n",
      " |  __itruediv__ = truediv(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  __mod__ = mod(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  __mul__ = mul(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  __pow__ = pow(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  __radd__ = radd(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  __rdiv__ = rtruediv(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  __rdivmod__(self, left) -> 'tuple[DataFrame, DataFrame]'\n",
      " |      Return integer division and modulo of Series and `left` (binary operator `divmod`).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      left : Series or scalar value\n",
      " |          The second operand to perform computation.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      tuple of two DataFrames\n",
      " |\n",
      " |  __reduce__(self)\n",
      " |      Helper for pickle.\n",
      " |\n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return a string representation for a particular ``DataFrame``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |\n",
      " |  __rfloordiv__ = rfloordiv(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  __rmod__ = rmod(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  __rmul__ = rmul(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  __round__(self, decimals=0) -> 'DataFrame'\n",
      " |      Round each value in a ``DataFrame`` to the given number of decimals.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      decimals : int, default: 0\n",
      " |          Number of decimal places to round to.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |\n",
      " |  __rpow__ = rpow(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  __rsub__ = rsub(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  __rtruediv__ = rtruediv(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  __setattr__(self, key, value) -> 'None'\n",
      " |      Set attribute `value` identified by `key`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : hashable\n",
      " |          Key to set.\n",
      " |      value : Any\n",
      " |          Value to set.\n",
      " |\n",
      " |  __setitem__(self, key, value) -> 'None'\n",
      " |      Set attribute `value` identified by `key`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : Any\n",
      " |          Key to set.\n",
      " |      value : Any\n",
      " |          Value to set.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      None\n",
      " |\n",
      " |  __sub__ = sub(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  __truediv__ = truediv(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  add(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get addition of ``DataFrame`` and `other`, element-wise (binary operator `add`).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.add <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.add.html>`_ for more.\n",
      " |\n",
      " |  add_prefix(self, prefix, axis=None) -> 'DataFrame'\n",
      " |      Prefix labels with string `prefix`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.add_prefix <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.add_prefix.html>`_ for more.\n",
      " |\n",
      " |  add_suffix(self, suffix, axis=None) -> 'DataFrame'\n",
      " |      Suffix labels with string `suffix`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.add_suffix <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.add_suffix.html>`_ for more.\n",
      " |\n",
      " |  apply(self, func, axis=0, raw=False, result_type=None, args=(), by_row='compat', engine='python', engine_kwargs=None, **kwargs) -> 'Union[DataFrame, Series]'\n",
      " |      Apply a function along an axis of the ``DataFrame``.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.apply <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.apply.html>`_ for more.\n",
      " |\n",
      " |  applymap(self, func, na_action: 'Optional[str]' = None, **kwargs) -> 'DataFrame'\n",
      " |      Apply a function to a Dataframe elementwise.\n",
      " |\n",
      " |      .. deprecated:: 2.1.0\n",
      " |\n",
      " |         DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      " |\n",
      " |      This method applies a function that accepts and returns a scalar\n",
      " |      to every element of a DataFrame.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable\n",
      " |          Python function, returns a single value from a single value.\n",
      " |      na_action : {None, 'ignore'}, default None\n",
      " |          If 'ignore', propagate NaN values, without passing them to func.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to pass as keywords arguments to\n",
      " |          `func`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Transformed DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Apply a function along input axis of DataFrame.\n",
      " |      DataFrame.map : Apply a function along input axis of DataFrame.\n",
      " |      DataFrame.replace: Replace values given in `to_replace` with `value`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n",
      " |      >>> df\n",
      " |             0      1\n",
      " |      0  1.000  2.120\n",
      " |      1  3.356  4.567\n",
      " |\n",
      " |      >>> df.map(lambda x: len(str(x)))\n",
      " |         0  1\n",
      " |      0  3  4\n",
      " |      1  5  5\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.applymap <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.applymap.html>`_ for more.\n",
      " |\n",
      " |  assign(self, **kwargs) -> 'DataFrame'\n",
      " |      Assign new columns to a ``DataFrame``.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.assign <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.assign.html>`_ for more.\n",
      " |\n",
      " |  boxplot(self, column=None, by=None, ax=None, fontsize=None, rot=0, grid=True, figsize=None, layout=None, return_type=None, backend=None, **kwargs)\n",
      " |      Make a box plot from ``DataFrame`` columns.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.boxplot <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.boxplot.html>`_ for more.\n",
      " |\n",
      " |  combine(self, other, func, fill_value=None, overwrite=True) -> 'DataFrame'\n",
      " |      Perform column-wise combine with another ``DataFrame``.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.combine <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.combine.html>`_ for more.\n",
      " |\n",
      " |  compare(self, other, align_axis=1, keep_shape: 'bool' = False, keep_equal: 'bool' = False, result_names=('self', 'other')) -> 'DataFrame'\n",
      " |      Compare to another ``DataFrame`` and show the differences.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.compare <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.compare.html>`_ for more.\n",
      " |\n",
      " |  corr(self, method='pearson', min_periods=1, numeric_only=False) -> 'DataFrame'\n",
      " |      Compute pairwise correlation of columns, excluding NA/null values.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.corr <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.corr.html>`_ for more.\n",
      " |\n",
      " |  corrwith(self, other, axis=0, drop=False, method='pearson', numeric_only=False) -> 'Series'\n",
      " |      Compute pairwise correlation.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.corrwith <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.corrwith.html>`_ for more.\n",
      " |\n",
      " |  cov(self, min_periods=None, ddof: 'Optional[int]' = 1, numeric_only=False) -> 'DataFrame'\n",
      " |      Compute pairwise covariance of columns, excluding NA/null values.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.cov <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.cov.html>`_ for more.\n",
      " |\n",
      " |  div = truediv(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  divide = truediv(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  dot(self, other) -> 'Union[DataFrame, Series]'\n",
      " |      Compute the matrix multiplication between the ``DataFrame`` and `other`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.dot <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.dot.html>`_ for more.\n",
      " |\n",
      " |  drop_duplicates(self, subset=None, *, keep='first', inplace=False, ignore_index=False) -> 'Union[DataFrame, None]'\n",
      " |      Return ``DataFrame`` with duplicate rows removed.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.drop_duplicates <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.drop_duplicates.html>`_ for more.\n",
      " |\n",
      " |  duplicated(self, subset=None, keep='first') -> 'Series'\n",
      " |      Return boolean ``Series`` denoting duplicate rows.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.duplicated <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.duplicated.html>`_ for more.\n",
      " |\n",
      " |  eq(self, other, axis='columns', level=None) -> 'DataFrame'\n",
      " |      Perform equality comparison of ``DataFrame`` and `other` (binary operator `eq`).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.eq <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.eq.html>`_ for more.\n",
      " |\n",
      " |  equals(self, other) -> 'bool'\n",
      " |      Test whether two objects contain the same elements.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.equals <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.equals.html>`_ for more.\n",
      " |\n",
      " |  eval(self, expr, inplace=False, **kwargs)\n",
      " |      Evaluate a string describing operations on ``DataFrame`` columns.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.eval <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.eval.html>`_ for more.\n",
      " |\n",
      " |  fillna(self, value=None, *, method=None, axis=None, inplace=False, limit=None, downcast=<no_default>) -> 'Union[DataFrame, None]'\n",
      " |      Fill NA/NaN values using the specified method.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.fillna <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.fillna.html>`_ for more.\n",
      " |\n",
      " |  floordiv(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get integer division of ``DataFrame`` and `other`, element-wise (binary operator `floordiv`).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.floordiv <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.floordiv.html>`_ for more.\n",
      " |\n",
      " |  ge(self, other, axis='columns', level=None) -> 'DataFrame'\n",
      " |      Get greater than or equal comparison of ``DataFrame`` and `other`, element-wise (binary operator `ge`).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.ge <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.ge.html>`_ for more.\n",
      " |\n",
      " |  groupby(self, by=None, axis=<no_default>, level=None, as_index=True, sort=True, group_keys=True, observed=<no_default>, dropna: 'bool' = True)\n",
      " |      Group ``DataFrame`` using a mapper or by a ``Series`` of columns.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.groupby <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.groupby.html>`_ for more.\n",
      " |\n",
      " |  gt(self, other, axis='columns', level=None) -> 'DataFrame'\n",
      " |      Get greater than comparison of ``DataFrame`` and `other`, element-wise (binary operator `ge`).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.gt <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.gt.html>`_ for more.\n",
      " |\n",
      " |  hist(data, column: 'IndexLabel | None' = None, by=None, grid: 'bool' = True, xlabelsize: 'int | None' = None, xrot: 'float | None' = None, ylabelsize: 'int | None' = None, yrot: 'float | None' = None, ax=None, sharex: 'bool' = False, sharey: 'bool' = False, figsize: 'tuple[int, int] | None' = None, layout: 'tuple[int, int] | None' = None, bins: 'int | Sequence[int]' = 10, backend: 'str | None' = None, legend: 'bool' = False, **kwargs)\n",
      " |      Make a histogram of the ``DataFrame``.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.hist <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.hist.html>`_ for more.\n",
      " |\n",
      " |  info(self, verbose: 'Optional[bool]' = None, buf: 'Optional[IO[str]]' = None, max_cols: 'Optional[int]' = None, memory_usage: 'Optional[Union[bool, str]]' = None, show_counts: 'Optional[bool]' = None) -> 'None'\n",
      " |      Print a concise summary of the ``DataFrame``.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.info <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.info.html>`_ for more.\n",
      " |\n",
      " |  insert(self, loc, column, value, allow_duplicates=<no_default>) -> 'None'\n",
      " |      Insert column into ``DataFrame`` at specified location.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.insert <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.insert.html>`_ for more.\n",
      " |\n",
      " |  isetitem(self, loc, value) -> 'None'\n",
      " |      Set the given value in the column with position `loc`.\n",
      " |\n",
      " |      This is a positional analogue to ``__setitem__``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      loc : int or sequence of ints\n",
      " |          Index position for the column.\n",
      " |      value : scalar or arraylike\n",
      " |          Value(s) for the column.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.isetitem <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.isetitem.html>`_ for more.\n",
      " |      ``frame.isetitem(loc, value)`` is an in-place method as it will\n",
      " |      modify the DataFrame in place (not returning a new object). In contrast to\n",
      " |      ``frame.iloc[:, i] = value`` which will try to update the existing values in\n",
      " |      place, ``frame.isetitem(loc, value)`` will not update the values of the column\n",
      " |      itself in place, it will instead insert a new array.\n",
      " |\n",
      " |      In cases where ``frame.columns`` is unique, this is equivalent to\n",
      " |      ``frame[frame.columns[i]] = value``.\n",
      " |\n",
      " |  isna(self) -> 'DataFrame'\n",
      " |      Detect missing values.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The result of detecting missing values.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.isna <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.isna.html>`_ for more.\n",
      " |\n",
      " |  isnull(self) -> 'DataFrame'\n",
      " |      Detect missing values.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The result of detecting missing values.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.isnull <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.isnull.html>`_ for more.\n",
      " |\n",
      " |  items(self) -> 'Iterable[tuple[Hashable, Series]]'\n",
      " |      Iterate over (column name, ``Series``) pairs.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.items <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.items.html>`_ for more.\n",
      " |\n",
      " |  iterrows(self) -> 'Iterable[tuple[Hashable, Series]]'\n",
      " |      Iterate over ``DataFrame`` rows as (index, ``Series``) pairs.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.iterrows <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.iterrows.html>`_ for more.\n",
      " |\n",
      " |  itertuples(self, index=True, name='Pandas') -> 'Iterable[tuple[Any, ...]]'\n",
      " |      Iterate over ``DataFrame`` rows as ``namedtuple``-s.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.itertuples <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.itertuples.html>`_ for more.\n",
      " |\n",
      " |  join(self, other, on=None, how='left', lsuffix='', rsuffix='', sort=False, validate=None) -> 'DataFrame'\n",
      " |      Join columns of another ``DataFrame``.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.join <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.join.html>`_ for more.\n",
      " |\n",
      " |  keys(self) -> 'pandas.Index'\n",
      " |      Get columns of the ``DataFrame``.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.keys <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.keys.html>`_ for more.\n",
      " |\n",
      " |  le(self, other, axis='columns', level=None) -> 'DataFrame'\n",
      " |      Get less than or equal comparison of ``DataFrame`` and `other`, element-wise (binary operator `le`).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.le <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.le.html>`_ for more.\n",
      " |\n",
      " |  lt(self, other, axis='columns', level=None) -> 'DataFrame'\n",
      " |      Get less than comparison of ``DataFrame`` and `other`, element-wise (binary operator `le`).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.lt <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.lt.html>`_ for more.\n",
      " |\n",
      " |  map(self, func, na_action: 'Optional[str]' = None, **kwargs) -> 'DataFrame'\n",
      " |      Apply a function to a Dataframe elementwise.\n",
      " |\n",
      " |      .. versionadded:: 2.1.0\n",
      " |\n",
      " |         DataFrame.applymap was deprecated and renamed to DataFrame.map.\n",
      " |\n",
      " |      This method applies a function that accepts and returns a scalar\n",
      " |      to every element of a DataFrame.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable\n",
      " |          Python function, returns a single value from a single value.\n",
      " |      na_action : {None, 'ignore'}, default None\n",
      " |          If 'ignore', propagate NaN values, without passing them to func.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to pass as keywords arguments to\n",
      " |          `func`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Transformed DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply : Apply a function along input axis of DataFrame.\n",
      " |      DataFrame.replace: Replace values given in `to_replace` with `value`.\n",
      " |      Series.map : Apply a function elementwise on a Series.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\n",
      " |      >>> df\n",
      " |             0      1\n",
      " |      0  1.000  2.120\n",
      " |      1  3.356  4.567\n",
      " |\n",
      " |      >>> df.map(lambda x: len(str(x)))\n",
      " |         0  1\n",
      " |      0  3  4\n",
      " |      1  5  5\n",
      " |\n",
      " |      Like Series.map, NA values can be ignored:\n",
      " |\n",
      " |      >>> df_copy = df.copy()\n",
      " |      >>> df_copy.iloc[0, 0] = pd.NA\n",
      " |      >>> df_copy.map(lambda x: len(str(x)), na_action='ignore')\n",
      " |           0  1\n",
      " |      0  NaN  4\n",
      " |      1  5.0  5\n",
      " |\n",
      " |      It is also possible to use `map` with functions that are not\n",
      " |      `lambda` functions:\n",
      " |\n",
      " |      >>> df.map(round, ndigits=1)\n",
      " |           0    1\n",
      " |      0  1.0  2.1\n",
      " |      1  3.4  4.6\n",
      " |\n",
      " |      Note that a vectorized version of `func` often exists, which will\n",
      " |      be much faster. You could square each number elementwise.\n",
      " |\n",
      " |      >>> df.map(lambda x: x**2)\n",
      " |                 0          1\n",
      " |      0   1.000000   4.494400\n",
      " |      1  11.262736  20.857489\n",
      " |\n",
      " |      But it's better to avoid map in that case.\n",
      " |\n",
      " |      >>> df ** 2\n",
      " |                 0          1\n",
      " |      0   1.000000   4.494400\n",
      " |      1  11.262736  20.857489\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.map <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.map.html>`_ for more.\n",
      " |\n",
      " |  melt(self, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None, ignore_index=True) -> 'DataFrame'\n",
      " |      Unpivot a ``DataFrame`` from wide to long format, optionally leaving identifiers set.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.melt <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.melt.html>`_ for more.\n",
      " |\n",
      " |  merge(self, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=None, indicator=False, validate=None) -> 'DataFrame'\n",
      " |      Merge ``DataFrame`` or named ``Series`` objects with a database-style join.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.merge <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.merge.html>`_ for more.\n",
      " |\n",
      " |  mod(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get modulo of ``DataFrame`` and `other`, element-wise (binary operator `mod`).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.mod <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.mod.html>`_ for more.\n",
      " |\n",
      " |  mul(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get multiplication of ``DataFrame`` and `other`, element-wise (binary operator `mul`).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.mul <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.mul.html>`_ for more.\n",
      " |\n",
      " |  multiply = mul(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  ne(self, other, axis='columns', level=None) -> 'DataFrame'\n",
      " |      Get not equal comparison of ``DataFrame`` and `other`, element-wise (binary operator `ne`).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.ne <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.ne.html>`_ for more.\n",
      " |\n",
      " |  nlargest(self, n, columns, keep='first') -> 'DataFrame'\n",
      " |      Return the first `n` rows ordered by `columns` in descending order.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.nlargest <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.nlargest.html>`_ for more.\n",
      " |\n",
      " |  nsmallest(self, n, columns, keep='first') -> 'DataFrame'\n",
      " |      Return the first `n` rows ordered by `columns` in ascending order.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.nsmallest <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.nsmallest.html>`_ for more.\n",
      " |\n",
      " |  pivot(self, *, columns, index=<no_default>, values=<no_default>) -> 'DataFrame'\n",
      " |      Return reshaped ``DataFrame`` organized by given index / column values.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.pivot <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.pivot.html>`_ for more.\n",
      " |\n",
      " |  pivot_table(self, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=<no_default>, sort=True) -> 'DataFrame'\n",
      " |      Create a spreadsheet-style pivot table as a ``DataFrame``.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.pivot_table <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.pivot_table.html>`_ for more.\n",
      " |\n",
      " |  pow(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get exponential power of ``DataFrame`` and `other`, element-wise (binary operator `pow`).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.pow <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.pow.html>`_ for more.\n",
      " |\n",
      " |  prod(self, axis=0, skipna=True, numeric_only=False, min_count=0, **kwargs)\n",
      " |      Return the product of the values over the requested axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.prod <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.prod.html>`_ for more.\n",
      " |\n",
      " |  product = prod(self, axis=0, skipna=True, numeric_only=False, min_count=0, **kwargs)\n",
      " |\n",
      " |  quantile(self, q=0.5, axis=0, numeric_only=False, interpolation='linear', method='single') -> 'Union[DataFrame, Series]'\n",
      " |      Return values at the given quantile over requested axis.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          Value between 0 <= q <= 1, the quantile(s) to compute.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Equals 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only `float`, `int` or `boolean` data.\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |              The default value of ``numeric_only`` is now ``False``.\n",
      " |\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |\n",
      " |          * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |            fractional part of the index surrounded by `i` and `j`.\n",
      " |          * lower: `i`.\n",
      " |          * higher: `j`.\n",
      " |          * nearest: `i` or `j` whichever is nearest.\n",
      " |          * midpoint: (`i` + `j`) / 2.\n",
      " |      method : {'single', 'table'}, default 'single'\n",
      " |          Whether to compute quantiles per-column ('single') or over all columns\n",
      " |          ('table'). When 'table', the only allowed interpolation methods are\n",
      " |          'nearest', 'lower', and 'higher'.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |\n",
      " |          If ``q`` is an array, a DataFrame will be returned where the\n",
      " |            index is ``q``, the columns are the columns of self, and the\n",
      " |            values are the quantiles.\n",
      " |          If ``q`` is a float, a Series will be returned where the\n",
      " |            index is the columns of self and the values are the quantiles.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.rolling.Rolling.quantile: Rolling quantile.\n",
      " |      numpy.percentile: Numpy function to compute the percentile.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n",
      " |      ...                   columns=['a', 'b'])\n",
      " |      >>> df.quantile(.1)\n",
      " |      a    1.3\n",
      " |      b    3.7\n",
      " |      Name: 0.1, dtype: float64\n",
      " |      >>> df.quantile([.1, .5])\n",
      " |             a     b\n",
      " |      0.1  1.3   3.7\n",
      " |      0.5  2.5  55.0\n",
      " |\n",
      " |      Specifying `method='table'` will compute the quantile over all columns.\n",
      " |\n",
      " |      >>> df.quantile(.1, method=\"table\", interpolation=\"nearest\")\n",
      " |      a    1\n",
      " |      b    1\n",
      " |      Name: 0.1, dtype: int64\n",
      " |      >>> df.quantile([.1, .5], method=\"table\", interpolation=\"nearest\")\n",
      " |           a    b\n",
      " |      0.1  1    1\n",
      " |      0.5  3  100\n",
      " |\n",
      " |      Specifying `numeric_only=False` will also compute the quantile of\n",
      " |      datetime and timedelta data.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2],\n",
      " |      ...                    'B': [pd.Timestamp('2010'),\n",
      " |      ...                          pd.Timestamp('2011')],\n",
      " |      ...                    'C': [pd.Timedelta('1 days'),\n",
      " |      ...                          pd.Timedelta('2 days')]})\n",
      " |      >>> df.quantile(0.5, numeric_only=False)\n",
      " |      A                    1.5\n",
      " |      B    2010-07-02 12:00:00\n",
      " |      C        1 days 12:00:00\n",
      " |      Name: 0.5, dtype: object\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.quantile <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.quantile.html>`_ for more.\n",
      " |\n",
      " |  query(self, expr, inplace=False, **kwargs) -> 'Union[DataFrame, None]'\n",
      " |      Query the columns of a ``DataFrame`` with a boolean expression.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.query <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.query.html>`_ for more.\n",
      " |\n",
      " |  radd(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get addition of ``DataFrame`` and `other`, element-wise (binary operator `radd`).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.radd <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.radd.html>`_ for more.\n",
      " |\n",
      " |  rdiv = rtruediv(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  reindex(self, labels=None, *, index=None, columns=None, axis=None, method=None, copy=None, level=None, fill_value=nan, limit=None, tolerance=None) -> 'DataFrame'\n",
      " |      Conform DataFrame to new index with optional filling logic.\n",
      " |\n",
      " |      Places NA/NaN in locations having no value in the previous index. A new object\n",
      " |      is produced unless the new index is equivalent to the current one and\n",
      " |      ``copy=False``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |\n",
      " |      labels : array-like, optional\n",
      " |          New labels / index to conform the axis specified by 'axis' to.\n",
      " |      index : array-like, optional\n",
      " |          New labels for the index. Preferably an Index object to avoid\n",
      " |          duplicating data.\n",
      " |      columns : array-like, optional\n",
      " |          New labels for the columns. Preferably an Index object to avoid\n",
      " |          duplicating data.\n",
      " |      axis : int or str, optional\n",
      " |          Axis to target. Can be either the axis name ('index', 'columns')\n",
      " |          or number (0, 1).\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}\n",
      " |          Method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |\n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: Propagate last valid observation forward to next\n",
      " |            valid.\n",
      " |          * backfill / bfill: Use next valid observation to fill gap.\n",
      " |          * nearest: Use nearest valid observations to fill gap.\n",
      " |\n",
      " |      copy : bool, default True\n",
      " |          Return a new object, even if the passed indexes are the same.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : scalar, default np.nan\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value.\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive elements to forward or backward fill.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |\n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame with changed index.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Set row labels.\n",
      " |      DataFrame.reset_index : Remove row labels or move them to new columns.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      ``DataFrame.reindex`` supports two calling conventions\n",
      " |\n",
      " |      * ``(index=index_labels, columns=column_labels, ...)``\n",
      " |      * ``(labels, axis={'index', 'columns'}, ...)``\n",
      " |\n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |\n",
      " |      Create a dataframe with some fictional data.\n",
      " |\n",
      " |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      " |      >>> df = pd.DataFrame({'http_status': [200, 200, 404, 404, 301],\n",
      " |      ...                   'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      " |      ...                   index=index)\n",
      " |      >>> df\n",
      " |                 http_status  response_time\n",
      " |      Firefox            200           0.04\n",
      " |      Chrome             200           0.02\n",
      " |      Safari             404           0.07\n",
      " |      IE10               404           0.08\n",
      " |      Konqueror          301           1.00\n",
      " |\n",
      " |      Create a new index and reindex the dataframe. By default\n",
      " |      values in the new index that do not have corresponding\n",
      " |      records in the dataframe are assigned ``NaN``.\n",
      " |\n",
      " |      >>> new_index = ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      " |      ...              'Chrome']\n",
      " |      >>> df.reindex(new_index)\n",
      " |                     http_status  response_time\n",
      " |      Safari               404.0           0.07\n",
      " |      Iceweasel              NaN            NaN\n",
      " |      Comodo Dragon          NaN            NaN\n",
      " |      IE10                 404.0           0.08\n",
      " |      Chrome               200.0           0.02\n",
      " |\n",
      " |      We can fill in the missing values by passing a value to\n",
      " |      the keyword ``fill_value``. Because the index is not monotonically\n",
      " |      increasing or decreasing, we cannot use arguments to the keyword\n",
      " |      ``method`` to fill the ``NaN`` values.\n",
      " |\n",
      " |      >>> df.reindex(new_index, fill_value=0)\n",
      " |                     http_status  response_time\n",
      " |      Safari                 404           0.07\n",
      " |      Iceweasel                0           0.00\n",
      " |      Comodo Dragon            0           0.00\n",
      " |      IE10                   404           0.08\n",
      " |      Chrome                 200           0.02\n",
      " |\n",
      " |      >>> df.reindex(new_index, fill_value='missing')\n",
      " |                    http_status response_time\n",
      " |      Safari                404          0.07\n",
      " |      Iceweasel         missing       missing\n",
      " |      Comodo Dragon     missing       missing\n",
      " |      IE10                  404          0.08\n",
      " |      Chrome                200          0.02\n",
      " |\n",
      " |      We can also reindex the columns.\n",
      " |\n",
      " |      >>> df.reindex(columns=['http_status', 'user_agent'])\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |\n",
      " |      Or we can use \"axis-style\" keyword arguments\n",
      " |\n",
      " |      >>> df.reindex(['http_status', 'user_agent'], axis=\"columns\")\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |\n",
      " |      To further illustrate the filling functionality in\n",
      " |      ``reindex``, we will create a dataframe with a\n",
      " |      monotonically increasing index (for example, a sequence\n",
      " |      of dates).\n",
      " |\n",
      " |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      " |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      " |      ...                    index=date_index)\n",
      " |      >>> df2\n",
      " |                  prices\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |\n",
      " |      Suppose we decide to expand the dataframe to cover a wider\n",
      " |      date range.\n",
      " |\n",
      " |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      " |      >>> df2.reindex(date_index2)\n",
      " |                  prices\n",
      " |      2009-12-29     NaN\n",
      " |      2009-12-30     NaN\n",
      " |      2009-12-31     NaN\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      2010-01-07     NaN\n",
      " |\n",
      " |      The index entries that did not have a value in the original data frame\n",
      " |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      " |      If desired, we can fill in the missing values using one of several\n",
      " |      options.\n",
      " |\n",
      " |      For example, to back-propagate the last valid value to fill the ``NaN``\n",
      " |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      " |\n",
      " |      >>> df2.reindex(date_index2, method='bfill')\n",
      " |                  prices\n",
      " |      2009-12-29   100.0\n",
      " |      2009-12-30   100.0\n",
      " |      2009-12-31   100.0\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      2010-01-07     NaN\n",
      " |\n",
      " |      Please note that the ``NaN`` value present in the original dataframe\n",
      " |      (at index value 2010-01-03) will not be filled by any of the\n",
      " |      value propagation schemes. This is because filling while reindexing\n",
      " |      does not look at dataframe values, but only compares the original and\n",
      " |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      " |      in the original dataframe, use the ``fillna()`` method.\n",
      " |\n",
      " |      See the :ref:`user guide <basics.reindexing>` for more.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.reindex <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.reindex.html>`_ for more.\n",
      " |\n",
      " |  reindex_like(self: 'DataFrame', other, method=None, copy: 'Optional[bool]' = None, limit=None, tolerance=None) -> 'DataFrame'\n",
      " |      Return an object with matching indices as other object.\n",
      " |\n",
      " |      Conform the object to the same index on all axes. Optional\n",
      " |      filling logic, placing NaN in locations having no value\n",
      " |      in the previous index. A new object is produced unless the\n",
      " |      new index is equivalent to the current one and copy=False.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Object of the same data type\n",
      " |          Its row and column indices are used to define the new indices\n",
      " |          of this object.\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}\n",
      " |          Method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |\n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * backfill / bfill: use next valid observation to fill gap\n",
      " |          * nearest: use nearest valid observations to fill gap.\n",
      " |\n",
      " |      copy : bool, default True\n",
      " |          Return a new object, even if the passed indexes are the same.\n",
      " |\n",
      " |          .. note::\n",
      " |              The `copy` keyword will change behavior in pandas 3.0.\n",
      " |              `Copy-on-Write\n",
      " |              <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\n",
      " |              will be enabled by default, which means that all methods with a\n",
      " |              `copy` keyword will use a lazy copy mechanism to defer the copy and\n",
      " |              ignore the `copy` keyword. The `copy` keyword will be removed in a\n",
      " |              future version of pandas.\n",
      " |\n",
      " |              You can already get the future behavior and improvements through\n",
      " |              enabling copy on write ``pd.options.mode.copy_on_write = True``\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive labels to fill for inexact matches.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations must\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |\n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as caller, but with changed indices on each axis.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Set row labels.\n",
      " |      DataFrame.reset_index : Remove row labels or move them to new columns.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.reindex_like <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.reindex_like.html>`_ for more.\n",
      " |      Same as calling\n",
      " |      ``.reindex(index=other.index, columns=other.columns,...)``.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame([[24.3, 75.7, 'high'],\n",
      " |      ...                     [31, 87.8, 'high'],\n",
      " |      ...                     [22, 71.6, 'medium'],\n",
      " |      ...                     [35, 95, 'medium']],\n",
      " |      ...                    columns=['temp_celsius', 'temp_fahrenheit',\n",
      " |      ...                             'windspeed'],\n",
      " |      ...                    index=pd.date_range(start='2014-02-12',\n",
      " |      ...                                        end='2014-02-15', freq='D'))\n",
      " |\n",
      " |      >>> df1\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          24.3             75.7      high\n",
      " |      2014-02-13          31.0             87.8      high\n",
      " |      2014-02-14          22.0             71.6    medium\n",
      " |      2014-02-15          35.0             95.0    medium\n",
      " |\n",
      " |      >>> df2 = pd.DataFrame([[28, 'low'],\n",
      " |      ...                     [30, 'low'],\n",
      " |      ...                     [35.1, 'medium']],\n",
      " |      ...                    columns=['temp_celsius', 'windspeed'],\n",
      " |      ...                    index=pd.DatetimeIndex(['2014-02-12', '2014-02-13',\n",
      " |      ...                                            '2014-02-15']))\n",
      " |\n",
      " |      >>> df2\n",
      " |                  temp_celsius windspeed\n",
      " |      2014-02-12          28.0       low\n",
      " |      2014-02-13          30.0       low\n",
      " |      2014-02-15          35.1    medium\n",
      " |\n",
      " |      >>> df2.reindex_like(df1)\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          28.0              NaN       low\n",
      " |      2014-02-13          30.0              NaN       low\n",
      " |      2014-02-14           NaN              NaN       NaN\n",
      " |      2014-02-15          35.1              NaN    medium\n",
      " |\n",
      " |  rename(self, mapper=None, index=None, columns=None, axis=None, copy=None, inplace=False, level=None, errors='ignore') -> 'Union[DataFrame, None]'\n",
      " |      Alter axes labels.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.rename <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.rename.html>`_ for more.\n",
      " |\n",
      " |  replace(self, to_replace=None, value=<no_default>, *, inplace: 'bool' = False, limit=None, regex: 'bool' = False, method: 'str | lib.NoDefault' = <no_default>) -> 'Union[DataFrame, None]'\n",
      " |      Replace values given in `to_replace` with `value`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.replace <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.replace.html>`_ for more.\n",
      " |\n",
      " |  rfloordiv(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get integer division of ``DataFrame`` and `other`, element-wise (binary operator `rfloordiv`).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.rfloordiv <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.rfloordiv.html>`_ for more.\n",
      " |\n",
      " |  rmod(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get modulo of ``DataFrame`` and `other`, element-wise (binary operator `rmod`).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.rmod <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.rmod.html>`_ for more.\n",
      " |\n",
      " |  rmul(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get multiplication of ``DataFrame`` and `other`, element-wise (binary operator `mul`).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.rmul <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.rmul.html>`_ for more.\n",
      " |\n",
      " |  rpow(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get exponential power of ``DataFrame`` and `other`, element-wise (binary operator `rpow`).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.rpow <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.rpow.html>`_ for more.\n",
      " |\n",
      " |  rsub(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get subtraction of ``DataFrame`` and `other`, element-wise (binary operator `rsub`).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.rsub <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.rsub.html>`_ for more.\n",
      " |\n",
      " |  rtruediv(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get floating division of ``DataFrame`` and `other`, element-wise (binary operator `rtruediv`).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.rtruediv <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.rtruediv.html>`_ for more.\n",
      " |\n",
      " |  select_dtypes(self, include=None, exclude=None) -> 'DataFrame'\n",
      " |      Return a subset of the ``DataFrame``'s columns based on the column dtypes.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.select_dtypes <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.select_dtypes.html>`_ for more.\n",
      " |\n",
      " |  set_index(self, keys, *, drop=True, append=False, inplace=False, verify_integrity=False) -> 'Union[DataFrame, None]'\n",
      " |      Set the ``DataFrame`` index using existing columns.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.set_index <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.set_index.html>`_ for more.\n",
      " |\n",
      " |  squeeze(self, axis=None) -> 'Union[DataFrame, Series, Scalar]'\n",
      " |      Squeeze 1 dimensional axis objects into scalars.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.squeeze <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.squeeze.html>`_ for more.\n",
      " |\n",
      " |  stack(self, level=-1, dropna=<no_default>, sort=<no_default>, future_stack=False) -> 'Union[DataFrame, Series]'\n",
      " |      Stack the prescribed level(s) from columns to index.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.stack <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.stack.html>`_ for more.\n",
      " |\n",
      " |  sub(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get subtraction of ``DataFrame`` and `other`, element-wise (binary operator `sub`).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.sub <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.sub.html>`_ for more.\n",
      " |\n",
      " |  subtract = sub(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |\n",
      " |  sum(self, axis=0, skipna=True, numeric_only=False, min_count=0, **kwargs) -> 'Series'\n",
      " |      Return the sum of the values over the requested axis.\n",
      " |\n",
      " |      This is equivalent to the method ``numpy.sum``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          .. warning::\n",
      " |\n",
      " |              The behavior of DataFrame.sum with ``axis=None`` is deprecated,\n",
      " |              in a future version this will reduce over both axes and return a scalar\n",
      " |              To retain the old behavior, pass axis=0 (or do not pass axis).\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or scalar\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |\n",
      " |      >>> s.sum()\n",
      " |      14\n",
      " |\n",
      " |      By default, the sum of an empty or all-NA Series is ``0``.\n",
      " |\n",
      " |      >>> pd.Series([], dtype=\"float64\").sum()  # min_count=0 is the default\n",
      " |      0.0\n",
      " |\n",
      " |      This can be controlled with the ``min_count`` parameter. For example, if\n",
      " |      you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
      " |\n",
      " |      >>> pd.Series([], dtype=\"float64\").sum(min_count=1)\n",
      " |      nan\n",
      " |\n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |\n",
      " |      >>> pd.Series([np.nan]).sum()\n",
      " |      0.0\n",
      " |\n",
      " |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      " |      nan\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.sum <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.sum.html>`_ for more.\n",
      " |\n",
      " |  to_feather(self, path, **kwargs) -> 'None'\n",
      " |      Write a ``DataFrame`` to the binary Feather format.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_feather <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_feather.html>`_ for more.\n",
      " |\n",
      " |  to_gbq(self, destination_table, project_id=None, chunksize=None, reauth=False, if_exists='fail', auth_local_webserver=True, table_schema=None, location=None, progress_bar=True, credentials=None) -> 'None'\n",
      " |      Write a ``DataFrame`` to a Google BigQuery table.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_gbq <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_gbq.html>`_ for more.\n",
      " |\n",
      " |  to_html(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, max_rows=None, max_cols=None, show_dimensions=False, decimal='.', bold_rows=True, classes=None, escape=True, notebook=False, border=None, table_id=None, render_links=False, encoding=None) -> 'Union[str, None]'\n",
      " |      Render a ``DataFrame`` as an HTML table.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_html <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_html.html>`_ for more.\n",
      " |\n",
      " |  to_orc(self, path=None, *, engine='pyarrow', index=None, engine_kwargs=None) -> 'Union[bytes, None]'\n",
      " |      Write a DataFrame to the ORC format.\n",
      " |\n",
      " |      .. versionadded:: 1.5.0\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, file-like object or None, default None\n",
      " |          If a string, it will be used as Root Directory path\n",
      " |          when writing a partitioned dataset. By file-like object,\n",
      " |          we refer to objects with a write() method, such as a file handle\n",
      " |          (e.g. via builtin open function). If path is None,\n",
      " |          a bytes object is returned.\n",
      " |      engine : {'pyarrow'}, default 'pyarrow'\n",
      " |          ORC library to use.\n",
      " |      index : bool, optional\n",
      " |          If ``True``, include the dataframe's index(es) in the file output.\n",
      " |          If ``False``, they will not be written to the file.\n",
      " |          If ``None``, similar to ``infer`` the dataframe's index(es)\n",
      " |          will be saved. However, instead of being saved as values,\n",
      " |          the RangeIndex will be stored as a range in the metadata so it\n",
      " |          doesn't require much space and is faster. Other indexes will\n",
      " |          be included as columns in the file output.\n",
      " |      engine_kwargs : dict[str, Any] or None, default None\n",
      " |          Additional keyword arguments passed to :func:`pyarrow.orc.write_table`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bytes if no path argument is provided else None\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      NotImplementedError\n",
      " |          Dtype of one or more columns is category, unsigned integers, interval,\n",
      " |          period or sparse.\n",
      " |      ValueError\n",
      " |          engine is not pyarrow.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_orc : Read a ORC file.\n",
      " |      DataFrame.to_parquet : Write a parquet file.\n",
      " |      DataFrame.to_csv : Write a csv file.\n",
      " |      DataFrame.to_sql : Write to a sql table.\n",
      " |      DataFrame.to_hdf : Write to hdf.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_orc <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_orc.html>`_ for more.\n",
      " |      * Before using this function you should read the :ref:`user guide about\n",
      " |        ORC <io.orc>` and :ref:`install optional dependencies <install.warn_orc>`.\n",
      " |      * This function requires `pyarrow <https://arrow.apache.org/docs/python/>`_\n",
      " |        library.\n",
      " |      * For supported dtypes please refer to `supported ORC features in Arrow\n",
      " |        <https://arrow.apache.org/docs/cpp/orc.html#data-types>`__.\n",
      " |      * Currently timezones in datetime columns are not preserved when a\n",
      " |        dataframe is converted into ORC files.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [4, 3]})\n",
      " |      >>> df.to_orc('df.orc')  # doctest: +SKIP\n",
      " |      >>> pd.read_orc('df.orc')  # doctest: +SKIP\n",
      " |         col1  col2\n",
      " |      0     1     4\n",
      " |      1     2     3\n",
      " |\n",
      " |      If you want to get a buffer to the orc content you can write it to io.BytesIO\n",
      " |\n",
      " |      >>> import io\n",
      " |      >>> b = io.BytesIO(df.to_orc())  # doctest: +SKIP\n",
      " |      >>> b.seek(0)  # doctest: +SKIP\n",
      " |      0\n",
      " |      >>> content = b.read()  # doctest: +SKIP\n",
      " |\n",
      " |  to_parquet(self, path=None, engine='auto', compression='snappy', index=None, partition_cols=None, storage_options: 'StorageOptions' = None, **kwargs) -> 'Union[bytes, None]'\n",
      " |      Write a DataFrame to the binary parquet format.\n",
      " |\n",
      " |      This function writes the dataframe as a `parquet file\n",
      " |      <https://parquet.apache.org/>`_. You can choose different parquet\n",
      " |      backends, and have the option of compression. See\n",
      " |      :ref:`the user guide <io.parquet>` for more details.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, path object, file-like object, or None, default None\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a binary ``write()`` function. If None, the result is\n",
      " |          returned as bytes. If a string or path, it will be used as Root Directory\n",
      " |          path when writing a partitioned dataset.\n",
      " |      engine : {'auto', 'pyarrow', 'fastparquet'}, default 'auto'\n",
      " |          Parquet library to use. If 'auto', then the option\n",
      " |          ``io.parquet.engine`` is used. The default ``io.parquet.engine``\n",
      " |          behavior is to try 'pyarrow', falling back to 'fastparquet' if\n",
      " |          'pyarrow' is unavailable.\n",
      " |      compression : str or None, default 'snappy'\n",
      " |          Name of the compression to use. Use ``None`` for no compression.\n",
      " |          Supported options: 'snappy', 'gzip', 'brotli', 'lz4', 'zstd'.\n",
      " |      index : bool, default None\n",
      " |          If ``True``, include the dataframe's index(es) in the file output.\n",
      " |          If ``False``, they will not be written to the file.\n",
      " |          If ``None``, similar to ``True`` the dataframe's index(es)\n",
      " |          will be saved. However, instead of being saved as values,\n",
      " |          the RangeIndex will be stored as a range in the metadata so it\n",
      " |          doesn't require much space and is faster. Other indexes will\n",
      " |          be included as columns in the file output.\n",
      " |      partition_cols : list, optional, default None\n",
      " |          Column names by which to partition the dataset.\n",
      " |          Columns are partitioned in the order they are given.\n",
      " |          Must be None if path is not a string.\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |\n",
      " |      **kwargs\n",
      " |          Additional arguments passed to the parquet library. See\n",
      " |          :ref:`pandas io <io.parquet>` for more details.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bytes if no path argument is provided else None\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_parquet : Read a parquet file.\n",
      " |      DataFrame.to_orc : Write an orc file.\n",
      " |      DataFrame.to_csv : Write a csv file.\n",
      " |      DataFrame.to_sql : Write to a sql table.\n",
      " |      DataFrame.to_hdf : Write to hdf.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_parquet <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_parquet.html>`_ for more.\n",
      " |      This function requires either the `fastparquet\n",
      " |      <https://pypi.org/project/fastparquet>`_ or `pyarrow\n",
      " |      <https://arrow.apache.org/docs/python/>`_ library.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [3, 4]})\n",
      " |      >>> df.to_parquet('df.parquet.gzip',\n",
      " |      ...               compression='gzip')  # doctest: +SKIP\n",
      " |      >>> pd.read_parquet('df.parquet.gzip')  # doctest: +SKIP\n",
      " |         col1  col2\n",
      " |      0     1     3\n",
      " |      1     2     4\n",
      " |\n",
      " |      If you want to get a buffer to the parquet content you can use a io.BytesIO\n",
      " |      object, as long as you don't use partition_cols, which creates multiple files.\n",
      " |\n",
      " |      >>> import io\n",
      " |      >>> f = io.BytesIO()\n",
      " |      >>> df.to_parquet(f)\n",
      " |      >>> f.seek(0)\n",
      " |      0\n",
      " |      >>> content = f.read()\n",
      " |\n",
      " |  to_period(self, freq=None, axis=0, copy=None) -> 'DataFrame'\n",
      " |      Convert ``DataFrame`` from ``DatetimeIndex`` to ``PeriodIndex``.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_period <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_period.html>`_ for more.\n",
      " |\n",
      " |  to_records(self, index=True, column_dtypes=None, index_dtypes=None) -> 'np.rec.recarray'\n",
      " |      Convert ``DataFrame`` to a NumPy record array.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_records <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_records.html>`_ for more.\n",
      " |\n",
      " |  to_stata(self, path: 'FilePath | WriteBuffer[bytes]', *, convert_dates: 'dict[Hashable, str] | None' = None, write_index: 'bool' = True, byteorder: 'str | None' = None, time_stamp: 'datetime.datetime | None' = None, data_label: 'str | None' = None, variable_labels: 'dict[Hashable, str] | None' = None, version: 'int | None' = 114, convert_strl: 'Sequence[Hashable] | None' = None, compression: 'CompressionOptions' = 'infer', storage_options: 'StorageOptions' = None, value_labels: 'dict[Hashable, dict[float | int, str]] | None' = None) -> 'None'\n",
      " |      Export DataFrame object to Stata dta format.\n",
      " |\n",
      " |      Writes the DataFrame to a Stata dataset file.\n",
      " |      \"dta\" files contain a Stata dataset.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str, path object, or buffer\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a binary ``write()`` function.\n",
      " |\n",
      " |      convert_dates : dict\n",
      " |          Dictionary mapping columns containing datetime types to stata\n",
      " |          internal format to use when writing the dates. Options are 'tc',\n",
      " |          'td', 'tm', 'tw', 'th', 'tq', 'ty'. Column can be either an integer\n",
      " |          or a name. Datetime columns that do not have a conversion type\n",
      " |          specified will be converted to 'tc'. Raises NotImplementedError if\n",
      " |          a datetime column has timezone information.\n",
      " |      write_index : bool\n",
      " |          Write the index to Stata dataset.\n",
      " |      byteorder : str\n",
      " |          Can be \">\", \"<\", \"little\", or \"big\". default is `sys.byteorder`.\n",
      " |      time_stamp : datetime\n",
      " |          A datetime to use as file creation date.  Default is the current\n",
      " |          time.\n",
      " |      data_label : str, optional\n",
      " |          A label for the data set.  Must be 80 characters or smaller.\n",
      " |      variable_labels : dict\n",
      " |          Dictionary containing columns as keys and variable labels as\n",
      " |          values. Each label must be 80 characters or smaller.\n",
      " |      version : {114, 117, 118, 119, None}, default 114\n",
      " |          Version to use in the output dta file. Set to None to let pandas\n",
      " |          decide between 118 or 119 formats depending on the number of\n",
      " |          columns in the frame. Version 114 can be read by Stata 10 and\n",
      " |          later. Version 117 can be read by Stata 13 or later. Version 118\n",
      " |          is supported in Stata 14 and later. Version 119 is supported in\n",
      " |          Stata 15 and later. Version 114 limits string variables to 244\n",
      " |          characters or fewer while versions 117 and later allow strings\n",
      " |          with lengths up to 2,000,000 characters. Versions 118 and 119\n",
      " |          support Unicode characters, and version 119 supports more than\n",
      " |          32,767 variables.\n",
      " |\n",
      " |          Version 119 should usually only be used when the number of\n",
      " |          variables exceeds the capacity of dta format 118. Exporting\n",
      " |          smaller datasets in format 119 may have unintended consequences,\n",
      " |          and, as of November 2020, Stata SE cannot read version 119 files.\n",
      " |\n",
      " |      convert_strl : list, optional\n",
      " |          List of column names to convert to string columns to Stata StrL\n",
      " |          format. Only available if version is 117.  Storing strings in the\n",
      " |          StrL format can produce smaller dta files if strings have more than\n",
      " |          8 characters and values are repeated.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path' is\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      " |          (otherwise no compression).\n",
      " |          Set to ``None`` for no compression.\n",
      " |          Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      " |          other key-value pairs are forwarded to\n",
      " |          ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor``, ``lzma.LZMAFile`` or\n",
      " |          ``tarfile.TarFile``, respectively.\n",
      " |          As an example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |              Added support for `.tar` files.\n",
      " |\n",
      " |          .. versionchanged:: 1.4.0 Zstandard support.\n",
      " |\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |\n",
      " |      value_labels : dict of dicts\n",
      " |          Dictionary containing columns as keys and dictionaries of column value\n",
      " |          to labels as values. Labels for a single variable must be 32,000\n",
      " |          characters or smaller.\n",
      " |\n",
      " |          .. versionadded:: 1.4.0\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      NotImplementedError\n",
      " |          * If datetimes contain timezone information\n",
      " |          * Column dtype is not representable in Stata\n",
      " |      ValueError\n",
      " |          * Columns listed in convert_dates are neither datetime64[ns]\n",
      " |            or datetime.datetime\n",
      " |          * Column listed in convert_dates is not in DataFrame\n",
      " |          * Categorical label contains more than 32,000 characters\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_stata : Import Stata data files.\n",
      " |      io.stata.StataWriter : Low-level writer for Stata data files.\n",
      " |      io.stata.StataWriter117 : Low-level writer for version 117 files.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['falcon', 'parrot', 'falcon',\n",
      " |      ...                               'parrot'],\n",
      " |      ...                    'speed': [350, 18, 361, 15]})\n",
      " |      >>> df.to_stata('animals.dta')  # doctest: +SKIP\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_stata <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_stata.html>`_ for more.\n",
      " |\n",
      " |  to_timestamp(self, freq=None, how='start', axis=0, copy=None) -> 'DataFrame'\n",
      " |      Cast to DatetimeIndex of timestamps, at *beginning* of period.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_timestamp <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_timestamp.html>`_ for more.\n",
      " |\n",
      " |  to_xml(self, path_or_buffer=None, index=True, root_name='data', row_name='row', na_rep=None, attr_cols=None, elem_cols=None, namespaces=None, prefix=None, encoding='utf-8', xml_declaration=True, pretty_print=True, parser='lxml', stylesheet=None, compression='infer', storage_options=None) -> 'Union[str, None]'\n",
      " |      Render a DataFrame to an XML document.\n",
      " |\n",
      " |      .. versionadded:: 1.3.0\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buffer : str, path object, file-like object, or None, default None\n",
      " |          String, path object (implementing ``os.PathLike[str]``), or file-like\n",
      " |          object implementing a ``write()`` function. If None, the result is returned\n",
      " |          as a string.\n",
      " |      index : bool, default True\n",
      " |          Whether to include index in XML document.\n",
      " |      root_name : str, default 'data'\n",
      " |          The name of root element in XML document.\n",
      " |      row_name : str, default 'row'\n",
      " |          The name of row element in XML document.\n",
      " |      na_rep : str, optional\n",
      " |          Missing data representation.\n",
      " |      attr_cols : list-like, optional\n",
      " |          List of columns to write as attributes in row element.\n",
      " |          Hierarchical columns will be flattened with underscore\n",
      " |          delimiting the different levels.\n",
      " |      elem_cols : list-like, optional\n",
      " |          List of columns to write as children in row element. By default,\n",
      " |          all columns output as children of row element. Hierarchical\n",
      " |          columns will be flattened with underscore delimiting the\n",
      " |          different levels.\n",
      " |      namespaces : dict, optional\n",
      " |          All namespaces to be defined in root element. Keys of dict\n",
      " |          should be prefix names and values of dict corresponding URIs.\n",
      " |          Default namespaces should be given empty string key. For\n",
      " |          example, ::\n",
      " |\n",
      " |              namespaces = {\"\": \"https://example.com\"}\n",
      " |\n",
      " |      prefix : str, optional\n",
      " |          Namespace prefix to be used for every element and/or attribute\n",
      " |          in document. This should be one of the keys in ``namespaces``\n",
      " |          dict.\n",
      " |      encoding : str, default 'utf-8'\n",
      " |          Encoding of the resulting document.\n",
      " |      xml_declaration : bool, default True\n",
      " |          Whether to include the XML declaration at start of document.\n",
      " |      pretty_print : bool, default True\n",
      " |          Whether output should be pretty printed with indentation and\n",
      " |          line breaks.\n",
      " |      parser : {'lxml','etree'}, default 'lxml'\n",
      " |          Parser module to use for building of tree. Only 'lxml' and\n",
      " |          'etree' are supported. With 'lxml', the ability to use XSLT\n",
      " |          stylesheet is supported.\n",
      " |      stylesheet : str, path object or file-like object, optional\n",
      " |          A URL, file-like object, or a raw string containing an XSLT\n",
      " |          script used to transform the raw XML output. Script should use\n",
      " |          layout of elements and attributes from original output. This\n",
      " |          argument requires ``lxml`` to be installed. Only XSLT 1.0\n",
      " |          scripts and not later versions is currently supported.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path_or_buffer' is\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      " |          (otherwise no compression).\n",
      " |          Set to ``None`` for no compression.\n",
      " |          Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      " |          other key-value pairs are forwarded to\n",
      " |          ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor``, ``lzma.LZMAFile`` or\n",
      " |          ``tarfile.TarFile``, respectively.\n",
      " |          As an example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |              Added support for `.tar` files.\n",
      " |\n",
      " |          .. versionchanged:: 1.4.0 Zstandard support.\n",
      " |\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If ``io`` is None, returns the resulting XML format as a\n",
      " |          string. Otherwise returns None.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_json : Convert the pandas object to a JSON string.\n",
      " |      to_html : Convert DataFrame to a html.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'shape': ['square', 'circle', 'triangle'],\n",
      " |      ...                    'degrees': [360, 360, 180],\n",
      " |      ...                    'sides': [4, np.nan, 3]})\n",
      " |\n",
      " |      >>> df.to_xml()  # doctest: +SKIP\n",
      " |      <?xml version='1.0' encoding='utf-8'?>\n",
      " |      <data>\n",
      " |        <row>\n",
      " |          <index>0</index>\n",
      " |          <shape>square</shape>\n",
      " |          <degrees>360</degrees>\n",
      " |          <sides>4.0</sides>\n",
      " |        </row>\n",
      " |        <row>\n",
      " |          <index>1</index>\n",
      " |          <shape>circle</shape>\n",
      " |          <degrees>360</degrees>\n",
      " |          <sides/>\n",
      " |        </row>\n",
      " |        <row>\n",
      " |          <index>2</index>\n",
      " |          <shape>triangle</shape>\n",
      " |          <degrees>180</degrees>\n",
      " |          <sides>3.0</sides>\n",
      " |        </row>\n",
      " |      </data>\n",
      " |\n",
      " |      >>> df.to_xml(attr_cols=[\n",
      " |      ...           'index', 'shape', 'degrees', 'sides'\n",
      " |      ...           ])  # doctest: +SKIP\n",
      " |      <?xml version='1.0' encoding='utf-8'?>\n",
      " |      <data>\n",
      " |        <row index=\"0\" shape=\"square\" degrees=\"360\" sides=\"4.0\"/>\n",
      " |        <row index=\"1\" shape=\"circle\" degrees=\"360\"/>\n",
      " |        <row index=\"2\" shape=\"triangle\" degrees=\"180\" sides=\"3.0\"/>\n",
      " |      </data>\n",
      " |\n",
      " |      >>> df.to_xml(namespaces={\"doc\": \"https://example.com\"},\n",
      " |      ...           prefix=\"doc\")  # doctest: +SKIP\n",
      " |      <?xml version='1.0' encoding='utf-8'?>\n",
      " |      <doc:data xmlns:doc=\"https://example.com\">\n",
      " |        <doc:row>\n",
      " |          <doc:index>0</doc:index>\n",
      " |          <doc:shape>square</doc:shape>\n",
      " |          <doc:degrees>360</doc:degrees>\n",
      " |          <doc:sides>4.0</doc:sides>\n",
      " |        </doc:row>\n",
      " |        <doc:row>\n",
      " |          <doc:index>1</doc:index>\n",
      " |          <doc:shape>circle</doc:shape>\n",
      " |          <doc:degrees>360</doc:degrees>\n",
      " |          <doc:sides/>\n",
      " |        </doc:row>\n",
      " |        <doc:row>\n",
      " |          <doc:index>2</doc:index>\n",
      " |          <doc:shape>triangle</doc:shape>\n",
      " |          <doc:degrees>180</doc:degrees>\n",
      " |          <doc:sides>3.0</doc:sides>\n",
      " |        </doc:row>\n",
      " |      </doc:data>\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_xml <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_xml.html>`_ for more.\n",
      " |\n",
      " |  transpose(self, copy=False, *args) -> 'DataFrame'\n",
      " |      Transpose index and columns.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.transpose <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.transpose.html>`_ for more.\n",
      " |\n",
      " |  truediv(self, other, axis='columns', level=None, fill_value=None) -> 'DataFrame'\n",
      " |      Get floating division of ``DataFrame`` and `other`, element-wise (binary operator `truediv`).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.truediv <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.truediv.html>`_ for more.\n",
      " |\n",
      " |  unstack(self, level=-1, fill_value=None, sort=True) -> 'Union[DataFrame, Series]'\n",
      " |      Pivot a level of the (necessarily hierarchical) index labels.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.unstack <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.unstack.html>`_ for more.\n",
      " |\n",
      " |  update(self, other, join='left', overwrite=True, filter_func=None, errors='ignore') -> 'None'\n",
      " |      Modify in place using non-NA values from another ``DataFrame``.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.update <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.update.html>`_ for more.\n",
      " |\n",
      " |  where(self, cond, other=nan, *, inplace=False, axis=None, level=None) -> 'Union[DataFrame, None]'\n",
      " |      Replace values where the condition is False.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.where <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.where.html>`_ for more.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |\n",
      " |  from_dict(data, orient='columns', dtype=None, columns=None) -> 'DataFrame'\n",
      " |      Construct ``DataFrame`` from dict of array-like or dicts.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.from_dict <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.from_dict.html>`_ for more.\n",
      " |\n",
      " |  from_records(data, index=None, exclude=None, columns=None, coerce_float=False, nrows=None) -> 'DataFrame'\n",
      " |      Convert structured or record ndarray to ``DataFrame``.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.from_records <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.from_records.html>`_ for more.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |\n",
      " |  T\n",
      " |      Transpose index and columns.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.T <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.T.html>`_ for more.\n",
      " |\n",
      " |  attrs\n",
      " |      Return dictionary of global attributes of this dataset.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.attrs <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.attrs.html>`_ for more.\n",
      " |\n",
      " |  axes\n",
      " |      Return a list representing the axes of the ``DataFrame``.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.axes <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.axes.html>`_ for more.\n",
      " |\n",
      " |  dtypes\n",
      " |      Return the dtypes in the ``DataFrame``.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.dtypes <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.dtypes.html>`_ for more.\n",
      " |\n",
      " |  empty\n",
      " |      Indicate whether ``DataFrame`` is empty.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.empty <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.empty.html>`_ for more.\n",
      " |\n",
      " |  ndim\n",
      " |      Return the number of dimensions of the underlying data, by definition 2.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.ndim <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.ndim.html>`_ for more.\n",
      " |\n",
      " |  plot\n",
      " |      Make plots of ``DataFrame``.\n",
      " |\n",
      " |  shape\n",
      " |      Return a tuple representing the dimensionality of the ``DataFrame``.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.shape <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.shape.html>`_ for more.\n",
      " |\n",
      " |  style\n",
      " |      Return a Styler object.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.style <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.style.html>`_ for more.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |\n",
      " |  columns\n",
      " |      Get the columns for this ``DataFrame``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Index\n",
      " |          The union of all indexes across the partitions.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __annotations__ = {'T': 'DataFrame', 'columns': 'pandas.Index'}\n",
      " |\n",
      " |  sparse = <class 'modin.pandas.accessor.SparseFrameAccessor'>\n",
      " |      DataFrame accessor for sparse data.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"a\": [1, 2, 0, 0],\n",
      " |      ...                   \"b\": [3, 0, 0, 4]}, dtype=\"Sparse[int]\")\n",
      " |      >>> df.sparse.density\n",
      " |      0.5\n",
      " |\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from modin.pandas.base.BasePandasDataset:\n",
      " |\n",
      " |  __abs__(self) -> 'Self'\n",
      " |      Return a `BasePandasDataset` with absolute numeric value of each element.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      BasePandasDataset\n",
      " |          Object containing the absolute value of each element.\n",
      " |\n",
      " |  __and__(self, other) -> 'Self'\n",
      " |      Return union of BasePandasDataset and `other` (binary operator `and`).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : BasePandasDataset or scalar value\n",
      " |          The second operand to perform computation.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      BasePandasDataset\n",
      " |\n",
      " |  __array__(self, dtype=None) -> 'np.ndarray'\n",
      " |      Return the values as a NumPy array.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str or np.dtype, optional\n",
      " |          The dtype of returned array.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      arr : np.ndarray\n",
      " |          NumPy representation of Modin object.\n",
      " |\n",
      " |  __array_ufunc__(self, ufunc: 'np.ufunc', method: 'str', *inputs: 'Any', **kwargs: 'Any') -> 'DataFrame | Series | Any'\n",
      " |      Apply the `ufunc` to the `BasePandasDataset`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ufunc : np.ufunc\n",
      " |          The NumPy ufunc to apply.\n",
      " |      method : str\n",
      " |          The method to apply.\n",
      " |      *inputs : tuple\n",
      " |          The inputs to the ufunc.\n",
      " |      **kwargs : dict\n",
      " |          Additional keyword arguments.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      BasePandasDataset\n",
      " |          The result of the ufunc applied to the `BasePandasDataset`.\n",
      " |\n",
      " |  __bool__ = __nonzero__(self)\n",
      " |\n",
      " |  __constructor__ = <functools.cached_property object>\n",
      " |      Construct DataFrame or Series object depending on self type.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      modin.pandas.BasePandasDataset\n",
      " |          Constructed object.\n",
      " |\n",
      " |  __copy__(self, deep=True) -> 'Self'\n",
      " |      Return the copy of the `BasePandasDataset`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default: True\n",
      " |          Whether the copy should be deep or not.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      BasePandasDataset\n",
      " |\n",
      " |  __deepcopy__(self, memo=None) -> 'Self'\n",
      " |      Return the deep copy of the `BasePandasDataset`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      memo : Any, optional\n",
      " |         Deprecated parameter.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      BasePandasDataset\n",
      " |\n",
      " |  __eq__(self, other) -> 'Self'\n",
      " |      Return equality comparison of BasePandasDataset and `other` (binary operator `eq`).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : BasePandasDataset or scalar value\n",
      " |          The second operand to perform computation.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      BasePandasDataset\n",
      " |\n",
      " |  __finalize__(self, other, method=None, **kwargs) -> 'Self'\n",
      " |      Propagate metadata from `other` to `self`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : BasePandasDataset\n",
      " |          The object from which to get the attributes that we are going\n",
      " |          to propagate.\n",
      " |      method : str, optional\n",
      " |          A passed method name providing context on where `__finalize__`\n",
      " |          was called.\n",
      " |      **kwargs : dict\n",
      " |          Additional keywords arguments to be passed to `__finalize__`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      BasePandasDataset\n",
      " |\n",
      " |  __ge__(self, right) -> 'Self'\n",
      " |      Return greater than or equal comparison of BasePandasDataset and `right` (binary operator `ge`).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      right : BasePandasDataset or scalar value\n",
      " |          The second operand to perform computation.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      BasePandasDataset\n",
      " |\n",
      " |  __getattribute__(self, item) -> 'Any'\n",
      " |      Return item from the `BasePandasDataset`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      item : hashable\n",
      " |          Item to get.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Any\n",
      " |\n",
      " |  __getitem__(self, key) -> 'Self'\n",
      " |      Retrieve dataset according to `key`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : callable, scalar, slice, str or tuple\n",
      " |          The global row index to retrieve data from.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      BasePandasDataset\n",
      " |          Located dataset.\n",
      " |\n",
      " |  __gt__(self, right) -> 'Self'\n",
      " |      Return greater than comparison of BasePandasDataset and `right` (binary operator `gt`).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      right : BasePandasDataset or scalar value\n",
      " |          The second operand to perform computation.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      BasePandasDataset\n",
      " |\n",
      " |  __invert__(self) -> 'Self'\n",
      " |      Apply bitwise inverse to each element of the `BasePandasDataset`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      BasePandasDataset\n",
      " |          New BasePandasDataset containing bitwise inverse to each value.\n",
      " |\n",
      " |  __le__(self, right) -> 'Self'\n",
      " |      Return less than or equal comparison of BasePandasDataset and `right` (binary operator `le`).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      right : BasePandasDataset or scalar value\n",
      " |          The second operand to perform computation.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      BasePandasDataset\n",
      " |\n",
      " |  __len__(self) -> 'int'\n",
      " |      Return length of info axis.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |\n",
      " |  __lt__(self, right) -> 'Self'\n",
      " |      Return less than comparison of BasePandasDataset and `right` (binary operator `lt`).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      right : BasePandasDataset or scalar value\n",
      " |          The second operand to perform computation.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      BasePandasDataset\n",
      " |\n",
      " |  __matmul__(self, other) -> 'Self | np.ndarray | Scalar'\n",
      " |      Compute the matrix multiplication between the `BasePandasDataset` and `other`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : BasePandasDataset or array-like\n",
      " |          The other object to compute the matrix product with.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      BasePandasDataset, np.ndarray or scalar\n",
      " |\n",
      " |  __ne__(self, other) -> 'Self'\n",
      " |      Return not equal comparison of BasePandasDataset and `other` (binary operator `ne`).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : BasePandasDataset or scalar value\n",
      " |          The second operand to perform computation.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      BasePandasDataset\n",
      " |\n",
      " |  __neg__(self) -> 'Self'\n",
      " |      Change the sign for every value of self.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      BasePandasDataset\n",
      " |\n",
      " |  __nonzero__(self)\n",
      " |      Evaluate `BasePandasDataset` as boolean object.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          Always since truth value for self is ambiguous.\n",
      " |\n",
      " |  __or__(self, other) -> 'Self'\n",
      " |      Return disjunction of BasePandasDataset and `other` (binary operator `or`).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : BasePandasDataset or scalar value\n",
      " |          The second operand to perform computation.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      BasePandasDataset\n",
      " |\n",
      " |  __rand__(self, other) -> 'Self'\n",
      " |      Return union of BasePandasDataset and `other` (binary operator `rand`).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : BasePandasDataset or scalar value\n",
      " |          The second operand to perform computation.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      BasePandasDataset\n",
      " |\n",
      " |  __ror__(self, other) -> 'Self'\n",
      " |      Return disjunction of BasePandasDataset and `other` (binary operator `ror`).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : BasePandasDataset or scalar value\n",
      " |          The second operand to perform computation.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      BasePandasDataset\n",
      " |\n",
      " |  __rxor__(self, other) -> 'Self'\n",
      " |      Return exclusive disjunction of BasePandasDataset and `other` (binary operator `rxor`).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : BasePandasDataset or scalar value\n",
      " |          The second operand to perform computation.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      BasePandasDataset\n",
      " |\n",
      " |  __sizeof__(self) -> 'int'\n",
      " |      Generate the total memory usage for an `BasePandasDataset`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |\n",
      " |  __str__(self) -> 'str'\n",
      " |      Return str(self).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |\n",
      " |  __xor__(self, other) -> 'Self'\n",
      " |      Return exclusive disjunction of BasePandasDataset and `other` (binary operator `xor`).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : BasePandasDataset or scalar value\n",
      " |          The second operand to perform computation.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      BasePandasDataset\n",
      " |\n",
      " |  abs(self) -> 'Self'\n",
      " |      Return a `BasePandasDataset` with absolute numeric value of each element.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.abs <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.abs.html>`_, `pandas.Series.abs <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.abs.html>`_ for more.\n",
      " |\n",
      " |  agg = aggregate(self, func=None, axis=0, *args, **kwargs) -> 'DataFrame | Series | Scalar'\n",
      " |\n",
      " |  aggregate(self, func=None, axis=0, *args, **kwargs) -> 'DataFrame | Series | Scalar'\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.aggregate <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.aggregate.html>`_, `pandas.Series.aggregate <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.aggregate.html>`_ for more.\n",
      " |\n",
      " |  align(self, other, join='outer', axis=None, level=None, copy=None, fill_value=None, method=<no_default>, limit=<no_default>, fill_axis=<no_default>, broadcast_axis=<no_default>) -> 'tuple[Self, Self]'\n",
      " |      Align two objects on their axes with the specified join method.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.align <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.align.html>`_, `pandas.Series.align <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.align.html>`_ for more.\n",
      " |\n",
      " |  all(self, axis=0, bool_only=False, skipna=True, **kwargs) -> 'Self'\n",
      " |      Return whether all elements are True, potentially over an axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.all <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.all.html>`_, `pandas.Series.all <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.all.html>`_ for more.\n",
      " |\n",
      " |  any(self, *, axis=0, bool_only=False, skipna=True, **kwargs) -> 'Self'\n",
      " |      Return whether any element is True, potentially over an axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.any <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.any.html>`_, `pandas.Series.any <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.any.html>`_ for more.\n",
      " |\n",
      " |  asfreq(self, freq, method=None, how=None, normalize=False, fill_value=None) -> 'Self'\n",
      " |      Convert time series to specified frequency.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.asfreq <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.asfreq.html>`_, `pandas.Series.asfreq <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.asfreq.html>`_ for more.\n",
      " |\n",
      " |  asof(self, where, subset=None) -> 'Self'\n",
      " |      Return the last row(s) without any NaNs before `where`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.asof <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.asof.html>`_, `pandas.Series.asof <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.asof.html>`_ for more.\n",
      " |\n",
      " |  astype(self, dtype, copy=None, errors='raise') -> 'Self'\n",
      " |      Cast a Modin object to a specified dtype `dtype`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.astype <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.astype.html>`_, `pandas.Series.astype <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.astype.html>`_ for more.\n",
      " |\n",
      " |  at_time(self, time, asof=False, axis=None) -> 'Self'\n",
      " |      Select values at particular time of day (e.g., 9:30AM).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.at_time <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.at_time.html>`_, `pandas.Series.at_time <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.at_time.html>`_ for more.\n",
      " |\n",
      " |  backfill(self, *, axis=None, inplace=False, limit=None, downcast=<no_default>) -> 'Self'\n",
      " |      Synonym for `DataFrame.bfill`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.backfill <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.backfill.html>`_, `pandas.Series.backfill <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.backfill.html>`_ for more.\n",
      " |\n",
      " |  between_time(self, start_time, end_time, inclusive='both', axis=None) -> 'Self'\n",
      " |      Select values between particular times of the day (e.g., 9:00-9:30 AM).\n",
      " |\n",
      " |      By setting ``start_time`` to be later than ``end_time``,\n",
      " |      you can get the times that are *not* between the two times.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_time : datetime.time or str\n",
      " |          Initial time as a time filter limit.\n",
      " |      end_time : datetime.time or str\n",
      " |          End time as a time filter limit.\n",
      " |      inclusive : {\"both\", \"neither\", \"left\", \"right\"}, default \"both\"\n",
      " |          Include boundaries; whether to set each bound as closed or open.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Determine range time on index or columns value.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Data from the original object filtered to the specified dates range.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      DatetimeIndex.indexer_between_time : Get just the index locations for\n",
      " |          values between particular times of the day.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='1D20min')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      2018-04-12 01:00:00  4\n",
      " |\n",
      " |      >>> ts.between_time('0:15', '0:45')\n",
      " |                           A\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |\n",
      " |      You get the times that are *not* between two times by setting\n",
      " |      ``start_time`` later than ``end_time``:\n",
      " |\n",
      " |      >>> ts.between_time('0:45', '0:15')\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-12 01:00:00  4\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.between_time <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.between_time.html>`_ for more.\n",
      " |\n",
      " |  bfill(self, *, axis=None, inplace=False, limit=None, limit_area=None, downcast=<no_default>) -> 'Self'\n",
      " |      Synonym for `DataFrame.fillna` with ``method='bfill'``.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.bfill <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.bfill.html>`_, `pandas.Series.bfill <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.bfill.html>`_ for more.\n",
      " |\n",
      " |  bool(self) -> 'bool'\n",
      " |      Return the bool of a single element `BasePandasDataset`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.bool <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.bool.html>`_, `pandas.Series.bool <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.bool.html>`_ for more.\n",
      " |\n",
      " |  clip(self, lower=None, upper=None, *, axis=None, inplace=False, **kwargs) -> 'Self'\n",
      " |      Trim values at input threshold(s).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.clip <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.clip.html>`_, `pandas.Series.clip <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.clip.html>`_ for more.\n",
      " |\n",
      " |  combine_first(self, other) -> 'Self'\n",
      " |      Update null elements with value in the same location in `other`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.combine_first <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.combine_first.html>`_, `pandas.Series.combine_first <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.combine_first.html>`_ for more.\n",
      " |\n",
      " |  convert_dtypes(self, infer_objects: 'bool' = True, convert_string: 'bool' = True, convert_integer: 'bool' = True, convert_boolean: 'bool' = True, convert_floating: 'bool' = True, dtype_backend: 'DtypeBackend' = 'numpy_nullable') -> 'Self'\n",
      " |      Convert columns to best possible dtypes using dtypes supporting ``pd.NA``.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.convert_dtypes <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.convert_dtypes.html>`_, `pandas.Series.convert_dtypes <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.convert_dtypes.html>`_ for more.\n",
      " |\n",
      " |  copy(self, deep=True) -> 'Self'\n",
      " |      Make a copy of the object's metadata.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.copy <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.copy.html>`_, `pandas.Series.copy <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.copy.html>`_ for more.\n",
      " |\n",
      " |  count(self, axis=0, numeric_only=False) -> 'Series | Scalar'\n",
      " |      Count non-NA cells for `BasePandasDataset`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.count <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.count.html>`_, `pandas.Series.count <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.count.html>`_ for more.\n",
      " |\n",
      " |  cummax(self, axis=None, skipna=True, *args, **kwargs) -> 'Self'\n",
      " |      Return cumulative maximum over a `BasePandasDataset` axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.cummax <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.cummax.html>`_, `pandas.Series.cummax <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.cummax.html>`_ for more.\n",
      " |\n",
      " |  cummin(self, axis=None, skipna=True, *args, **kwargs) -> 'Self'\n",
      " |      Return cumulative minimum over a `BasePandasDataset` axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.cummin <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.cummin.html>`_, `pandas.Series.cummin <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.cummin.html>`_ for more.\n",
      " |\n",
      " |  cumprod(self, axis=None, skipna=True, *args, **kwargs) -> 'Self'\n",
      " |      Return cumulative product over a `BasePandasDataset` axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.cumprod <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.cumprod.html>`_, `pandas.Series.cumprod <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.cumprod.html>`_ for more.\n",
      " |\n",
      " |  cumsum(self, axis=None, skipna=True, *args, **kwargs) -> 'Self'\n",
      " |      Return cumulative sum over a `BasePandasDataset` axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.cumsum <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.cumsum.html>`_, `pandas.Series.cumsum <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.cumsum.html>`_ for more.\n",
      " |\n",
      " |  describe(self, percentiles=None, include=None, exclude=None) -> 'Self'\n",
      " |      Generate descriptive statistics.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.describe <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.describe.html>`_, `pandas.Series.describe <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.describe.html>`_ for more.\n",
      " |\n",
      " |  diff(self, periods=1, axis=0) -> 'Self'\n",
      " |      First discrete difference of element.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.diff <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.diff.html>`_, `pandas.Series.diff <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.diff.html>`_ for more.\n",
      " |\n",
      " |  drop(self, labels=None, *, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise') -> 'Self'\n",
      " |      Drop specified labels from `BasePandasDataset`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.drop <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.drop.html>`_, `pandas.Series.drop <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.drop.html>`_ for more.\n",
      " |\n",
      " |  droplevel(self, level, axis=0) -> 'Self'\n",
      " |      Return `BasePandasDataset` with requested index / column level(s) removed.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.droplevel <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.droplevel.html>`_, `pandas.Series.droplevel <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.droplevel.html>`_ for more.\n",
      " |\n",
      " |  dropna(self, *, axis: 'Axis' = 0, how: 'str | lib.NoDefault' = <no_default>, thresh: 'int | lib.NoDefault' = <no_default>, subset: 'IndexLabel' = None, inplace: 'bool' = False, ignore_index: 'bool' = False) -> 'Self'\n",
      " |      Remove missing values.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.dropna <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.dropna.html>`_, `pandas.Series.dropna <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.dropna.html>`_ for more.\n",
      " |\n",
      " |  ewm(self, com: 'float | None' = None, span: 'float | None' = None, halflife: 'float | TimedeltaConvertibleTypes | None' = None, alpha: 'float | None' = None, min_periods: 'int | None' = 0, adjust: 'bool' = True, ignore_na: 'bool' = False, axis: 'Axis' = <no_default>, times: 'str | np.ndarray | BasePandasDataset | None' = None, method: 'str' = 'single') -> 'pandas.core.window.ewm.ExponentialMovingWindow'\n",
      " |      Provide exponentially weighted (EW) calculations.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.ewm <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.ewm.html>`_, `pandas.Series.ewm <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.ewm.html>`_ for more.\n",
      " |\n",
      " |  expanding(self, min_periods=1, axis=<no_default>, method='single') -> 'Expanding'\n",
      " |      Provide expanding window calculations.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.expanding <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.expanding.html>`_, `pandas.Series.expanding <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.expanding.html>`_ for more.\n",
      " |\n",
      " |  explode(self, column, ignore_index: 'bool' = False) -> 'Self'\n",
      " |      Transform each element of a list-like to a row.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.explode <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.explode.html>`_, `pandas.Series.explode <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.explode.html>`_ for more.\n",
      " |\n",
      " |  ffill(self, *, axis=None, inplace=False, limit=None, limit_area=None, downcast=<no_default>) -> 'Self | None'\n",
      " |      Synonym for `DataFrame.fillna` with ``method='ffill'``.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.ffill <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.ffill.html>`_, `pandas.Series.ffill <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.ffill.html>`_ for more.\n",
      " |\n",
      " |  filter(self, items=None, like=None, regex=None, axis=None) -> 'Self'\n",
      " |      Subset the `BasePandasDataset` rows or columns according to the specified index labels.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.filter <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.filter.html>`_, `pandas.Series.filter <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.filter.html>`_ for more.\n",
      " |\n",
      " |  first(self, offset) -> 'Self | None'\n",
      " |      Select initial periods of time series data based on a date offset.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.first <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.first.html>`_, `pandas.Series.first <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.first.html>`_ for more.\n",
      " |\n",
      " |  first_valid_index(self) -> 'int'\n",
      " |      Return index for first non-NA value or None, if no non-NA value is found.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.first_valid_index <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.first_valid_index.html>`_, `pandas.Series.first_valid_index <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.first_valid_index.html>`_ for more.\n",
      " |\n",
      " |  get(self, key, default=None) -> 'DataFrame | Series | Scalar'\n",
      " |      Get item from object for given key.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.get <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.get.html>`_, `pandas.Series.get <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.get.html>`_ for more.\n",
      " |\n",
      " |  head(self, n=5) -> 'Self'\n",
      " |      Return the first `n` rows.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.head <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.head.html>`_, `pandas.Series.head <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.head.html>`_ for more.\n",
      " |\n",
      " |  idxmax(self, axis=0, skipna=True, numeric_only=False) -> 'Self'\n",
      " |      Return index of first occurrence of maximum over requested axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.idxmax <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.idxmax.html>`_, `pandas.Series.idxmax <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.idxmax.html>`_ for more.\n",
      " |\n",
      " |  idxmin(self, axis=0, skipna=True, numeric_only=False) -> 'Self'\n",
      " |      Return index of first occurrence of minimum over requested axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.idxmin <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.idxmin.html>`_, `pandas.Series.idxmin <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.idxmin.html>`_ for more.\n",
      " |\n",
      " |  infer_objects(self, copy=None) -> 'Self'\n",
      " |      Attempt to infer better dtypes for object columns.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.infer_objects <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.infer_objects.html>`_, `pandas.Series.infer_objects <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.infer_objects.html>`_ for more.\n",
      " |\n",
      " |  interpolate(self, method='linear', *, axis=0, limit=None, inplace=False, limit_direction: 'Optional[str]' = None, limit_area=None, downcast=<no_default>, **kwargs) -> 'Self'\n",
      " |      Fill NaN values using an interpolation method.\n",
      " |\n",
      " |      Please note that only ``method='linear'`` is supported for\n",
      " |      DataFrame/Series with a MultiIndex.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str, default 'linear'\n",
      " |          Interpolation technique to use. One of:\n",
      " |\n",
      " |          * 'linear': Ignore the index and treat the values as equally\n",
      " |            spaced. This is the only method supported on MultiIndexes.\n",
      " |          * 'time': Works on daily and higher resolution data to interpolate\n",
      " |            given length of interval.\n",
      " |          * 'index', 'values': use the actual numerical values of the index.\n",
      " |          * 'pad': Fill in NaNs using existing values.\n",
      " |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
      " |            'barycentric', 'polynomial': Passed to\n",
      " |            `scipy.interpolate.interp1d`, whereas 'spline' is passed to\n",
      " |            `scipy.interpolate.UnivariateSpline`. These methods use the numerical\n",
      " |            values of the index.  Both 'polynomial' and 'spline' require that\n",
      " |            you also specify an `order` (int), e.g.\n",
      " |            ``df.interpolate(method='polynomial', order=5)``. Note that,\n",
      " |            `slinear` method in Pandas refers to the Scipy first order `spline`\n",
      " |            instead of Pandas first order `spline`.\n",
      " |          * 'krogh', 'piecewise_polynomial', 'spline', 'pchip', 'akima',\n",
      " |            'cubicspline': Wrappers around the SciPy interpolation methods of\n",
      " |            similar names. See `Notes`.\n",
      " |          * 'from_derivatives': Refers to\n",
      " |            `scipy.interpolate.BPoly.from_derivatives`.\n",
      " |\n",
      " |      axis : {{0 or 'index', 1 or 'columns', None}}, default None\n",
      " |          Axis to interpolate along. For `Series` this parameter is unused\n",
      " |          and defaults to 0.\n",
      " |      limit : int, optional\n",
      " |          Maximum number of consecutive NaNs to fill. Must be greater than\n",
      " |          0.\n",
      " |      inplace : bool, default False\n",
      " |          Update the data in place if possible.\n",
      " |      limit_direction : {{'forward', 'backward', 'both'}}, Optional\n",
      " |          Consecutive NaNs will be filled in this direction.\n",
      " |\n",
      " |          If limit is specified:\n",
      " |              * If 'method' is 'pad' or 'ffill', 'limit_direction' must be 'forward'.\n",
      " |              * If 'method' is 'backfill' or 'bfill', 'limit_direction' must be\n",
      " |                'backwards'.\n",
      " |\n",
      " |          If 'limit' is not specified:\n",
      " |              * If 'method' is 'backfill' or 'bfill', the default is 'backward'\n",
      " |              * else the default is 'forward'\n",
      " |\n",
      " |          raises ValueError if `limit_direction` is 'forward' or 'both' and\n",
      " |              method is 'backfill' or 'bfill'.\n",
      " |          raises ValueError if `limit_direction` is 'backward' or 'both' and\n",
      " |              method is 'pad' or 'ffill'.\n",
      " |\n",
      " |      limit_area : {{`None`, 'inside', 'outside'}}, default None\n",
      " |          If limit is specified, consecutive NaNs will be filled with this\n",
      " |          restriction.\n",
      " |\n",
      " |          * ``None``: No fill restriction.\n",
      " |          * 'inside': Only fill NaNs surrounded by valid values\n",
      " |            (interpolate).\n",
      " |          * 'outside': Only fill NaNs outside valid values (extrapolate).\n",
      " |\n",
      " |      downcast : optional, 'infer' or None, defaults to None\n",
      " |          Downcast dtypes if possible.\n",
      " |\n",
      " |          .. deprecated:: 2.1.0\n",
      " |\n",
      " |      ``**kwargs`` : optional\n",
      " |          Keyword arguments to pass on to the interpolating function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame or None\n",
      " |          Returns the same object type as the caller, interpolated at\n",
      " |          some or all ``NaN`` values or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      fillna : Fill missing values using different methods.\n",
      " |      scipy.interpolate.Akima1DInterpolator : Piecewise cubic polynomials\n",
      " |          (Akima interpolator).\n",
      " |      scipy.interpolate.BPoly.from_derivatives : Piecewise polynomial in the\n",
      " |          Bernstein basis.\n",
      " |      scipy.interpolate.interp1d : Interpolate a 1-D function.\n",
      " |      scipy.interpolate.KroghInterpolator : Interpolate polynomial (Krogh\n",
      " |          interpolator).\n",
      " |      scipy.interpolate.PchipInterpolator : PCHIP 1-d monotonic cubic\n",
      " |          interpolation.\n",
      " |      scipy.interpolate.CubicSpline : Cubic spline data interpolator.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.interpolate <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.interpolate.html>`_, `pandas.Series.interpolate <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.interpolate.html>`_ for more.\n",
      " |      The 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima'\n",
      " |      methods are wrappers around the respective SciPy implementations of\n",
      " |      similar names. These use the actual numerical values of the index.\n",
      " |      For more information on their behavior, see the\n",
      " |      `SciPy documentation\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Filling in ``NaN`` in a :class:`~pandas.Series` via linear\n",
      " |      interpolation.\n",
      " |\n",
      " |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      " |      >>> s\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    NaN\n",
      " |      3    3.0\n",
      " |      dtype: float64\n",
      " |      >>> s.interpolate()\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Filling in ``NaN`` in a Series via polynomial interpolation or splines:\n",
      " |      Both 'polynomial' and 'spline' methods require that you also specify\n",
      " |      an ``order`` (int).\n",
      " |\n",
      " |      >>> s = pd.Series([0, 2, np.nan, 8])\n",
      " |      >>> s.interpolate(method='polynomial', order=2)\n",
      " |      0    0.000000\n",
      " |      1    2.000000\n",
      " |      2    4.666667\n",
      " |      3    8.000000\n",
      " |      dtype: float64\n",
      " |\n",
      " |      Fill the DataFrame forward (that is, going down) along each column\n",
      " |      using linear interpolation.\n",
      " |\n",
      " |      Note how the last entry in column 'a' is interpolated differently,\n",
      " |      because there is no entry after it to use for interpolation.\n",
      " |      Note how the first entry in column 'b' remains ``NaN``, because there\n",
      " |      is no entry before it to use for interpolation.\n",
      " |\n",
      " |      >>> df = pd.DataFrame([(0.0, np.nan, -1.0, 1.0),\n",
      " |      ...                    (np.nan, 2.0, np.nan, np.nan),\n",
      " |      ...                    (2.0, 3.0, np.nan, 9.0),\n",
      " |      ...                    (np.nan, 4.0, -4.0, 16.0)],\n",
      " |      ...                   columns=list('abcd'))\n",
      " |      >>> df\n",
      " |           a    b    c     d\n",
      " |      0  0.0  NaN -1.0   1.0\n",
      " |      1  NaN  2.0  NaN   NaN\n",
      " |      2  2.0  3.0  NaN   9.0\n",
      " |      3  NaN  4.0 -4.0  16.0\n",
      " |      >>> df.interpolate(method='linear', limit_direction='forward', axis=0)\n",
      " |           a    b    c     d\n",
      " |      0  0.0  NaN -1.0   1.0\n",
      " |      1  1.0  2.0 -2.0   5.0\n",
      " |      2  2.0  3.0 -3.0   9.0\n",
      " |      3  2.0  4.0 -4.0  16.0\n",
      " |\n",
      " |      Using polynomial interpolation.\n",
      " |\n",
      " |      >>> df['d'].interpolate(method='polynomial', order=2)\n",
      " |      0     1.0\n",
      " |      1     4.0\n",
      " |      2     9.0\n",
      " |      3    16.0\n",
      " |      Name: d, dtype: float64\n",
      " |\n",
      " |  isin(self, values) -> 'Self'\n",
      " |      Whether elements in `BasePandasDataset` are contained in `values`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.isin <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.isin.html>`_, `pandas.Series.isin <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.isin.html>`_ for more.\n",
      " |\n",
      " |  kurt(self, axis=0, skipna=True, numeric_only=False, **kwargs) -> 'Series | float'\n",
      " |      Return unbiased kurtosis over requested axis.\n",
      " |\n",
      " |      Kurtosis obtained using Fisher's definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |          Axis for the function to be applied on.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |\n",
      " |          For DataFrames, specifying ``axis=None`` will apply the aggregation\n",
      " |          across both axes.\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. Not implemented for Series.\n",
      " |\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or scalar\n",
      " |\n",
      " |                  Examples\n",
      " |                  --------\n",
      " |                  >>> s = pd.Series([1, 2, 2, 3], index=['cat', 'dog', 'dog', 'mouse'])\n",
      " |                  >>> s\n",
      " |                  cat    1\n",
      " |                  dog    2\n",
      " |                  dog    2\n",
      " |                  mouse  3\n",
      " |                  dtype: int64\n",
      " |                  >>> s.kurt()\n",
      " |                  1.5\n",
      " |\n",
      " |                  With a DataFrame\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2, 2, 3], 'b': [3, 4, 4, 4]},\n",
      " |                  ...                   index=['cat', 'dog', 'dog', 'mouse'])\n",
      " |                  >>> df\n",
      " |                         a   b\n",
      " |                    cat  1   3\n",
      " |                    dog  2   4\n",
      " |                    dog  2   4\n",
      " |                  mouse  3   4\n",
      " |                  >>> df.kurt()\n",
      " |                  a   1.5\n",
      " |                  b   4.0\n",
      " |                  dtype: float64\n",
      " |\n",
      " |                  With axis=None\n",
      " |\n",
      " |                  >>> df.kurt(axis=None).round(6)\n",
      " |                  -0.988693\n",
      " |\n",
      " |                  Using axis=1\n",
      " |\n",
      " |                  >>> df = pd.DataFrame({'a': [1, 2], 'b': [3, 4], 'c': [3, 4], 'd': [1, 2]},\n",
      " |                  ...                   index=['cat', 'dog'])\n",
      " |                  >>> df.kurt(axis=1)\n",
      " |                  cat   -6.0\n",
      " |                  dog   -6.0\n",
      " |                  dtype: float64\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.kurt <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.kurt.html>`_ for more.\n",
      " |\n",
      " |  kurtosis = kurt(self, axis=0, skipna=True, numeric_only=False, **kwargs) -> 'Series | float'\n",
      " |\n",
      " |  last(self, offset) -> 'Self'\n",
      " |      Select final periods of time series data based on a date offset.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.last <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.last.html>`_, `pandas.Series.last <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.last.html>`_ for more.\n",
      " |\n",
      " |  last_valid_index(self) -> 'int'\n",
      " |      Return index for last non-NA value or None, if no non-NA value is found.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.last_valid_index <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.last_valid_index.html>`_, `pandas.Series.last_valid_index <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.last_valid_index.html>`_ for more.\n",
      " |\n",
      " |  mask(self, cond, other=<no_default>, *, inplace: 'bool' = False, axis: 'Optional[Axis]' = None, level: 'Optional[Level]' = None) -> 'Self | None'\n",
      " |      Replace values where the condition is True.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.mask <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.mask.html>`_, `pandas.Series.mask <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.mask.html>`_ for more.\n",
      " |\n",
      " |  max(self, axis: 'Axis' = 0, skipna=True, numeric_only=False, **kwargs) -> 'Series | None'\n",
      " |      Return the maximum of the values over the requested axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.max <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.max.html>`_, `pandas.Series.max <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.max.html>`_ for more.\n",
      " |\n",
      " |  mean(self, axis: 'Axis' = 0, skipna=True, numeric_only=False, **kwargs) -> 'Series | float'\n",
      " |      Return the mean of the values over the requested axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.mean <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.mean.html>`_, `pandas.Series.mean <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.mean.html>`_ for more.\n",
      " |\n",
      " |  median(self, axis: 'Axis' = 0, skipna=True, numeric_only=False, **kwargs) -> 'Series | float'\n",
      " |      Return the mean of the values over the requested axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.median <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.median.html>`_, `pandas.Series.median <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.median.html>`_ for more.\n",
      " |\n",
      " |  memory_usage(self, index=True, deep=False) -> 'Series | None'\n",
      " |      Return the memory usage of the `BasePandasDataset`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.memory_usage <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.memory_usage.html>`_, `pandas.Series.memory_usage <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.memory_usage.html>`_ for more.\n",
      " |\n",
      " |  min(self, axis: 'Axis' = 0, skipna: 'bool' = True, numeric_only=False, **kwargs) -> 'Series | None'\n",
      " |      Return the minimum of the values over the requested axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.min <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.min.html>`_, `pandas.Series.min <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.min.html>`_ for more.\n",
      " |\n",
      " |  mode(self, axis=0, numeric_only=False, dropna=True) -> 'Self'\n",
      " |      Get the mode(s) of each element along the selected axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.mode <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.mode.html>`_, `pandas.Series.mode <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.mode.html>`_ for more.\n",
      " |\n",
      " |  notna(self) -> 'Self'\n",
      " |      Detect existing (non-missing) values.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.notna <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.notna.html>`_, `pandas.Series.notna <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.notna.html>`_ for more.\n",
      " |\n",
      " |  notnull = notna(self) -> 'Self'\n",
      " |\n",
      " |  nunique(self, axis=0, dropna=True) -> 'Series | int'\n",
      " |      Return number of unique elements in the `BasePandasDataset`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.nunique <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.nunique.html>`_, `pandas.Series.nunique <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.nunique.html>`_ for more.\n",
      " |\n",
      " |  pad(self, *, axis=None, inplace=False, limit=None, downcast=<no_default>) -> 'Self | None'\n",
      " |      Synonym for `DataFrame.ffill`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.pad <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.pad.html>`_, `pandas.Series.pad <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.pad.html>`_ for more.\n",
      " |\n",
      " |  pct_change(self, periods=1, fill_method=<no_default>, limit=<no_default>, freq=None, **kwargs) -> 'Self'\n",
      " |      Percentage change between the current and a prior element.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.pct_change <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.pct_change.html>`_, `pandas.Series.pct_change <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.pct_change.html>`_ for more.\n",
      " |\n",
      " |  pipe(self, func: 'Callable[..., T] | tuple[Callable[..., T], str]', *args, **kwargs) -> 'T'\n",
      " |      Apply chainable functions that expect `BasePandasDataset`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.pipe <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.pipe.html>`_, `pandas.Series.pipe <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.pipe.html>`_ for more.\n",
      " |\n",
      " |  pop(self, item) -> 'Series | Scalar'\n",
      " |      Return item and drop from frame. Raise KeyError if not found.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.pop <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.pop.html>`_, `pandas.Series.pop <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.pop.html>`_ for more.\n",
      " |\n",
      " |  rank(self, axis=0, method: 'str' = 'average', numeric_only=False, na_option: 'str' = 'keep', ascending: 'bool' = True, pct: 'bool' = False) -> 'Self'\n",
      " |      Compute numerical data ranks (1 through n) along axis.\n",
      " |\n",
      " |      By default, equal values are assigned a rank that is the average of the\n",
      " |      ranks of those values.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Index to direct ranking.\n",
      " |          For `Series` this parameter is unused and defaults to 0.\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n",
      " |          How to rank the group of records that have the same value (i.e. ties):\n",
      " |\n",
      " |          * average: average rank of the group\n",
      " |          * min: lowest rank in the group\n",
      " |          * max: highest rank in the group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups.\n",
      " |\n",
      " |      numeric_only : bool, default False\n",
      " |          For DataFrame objects, rank only numeric columns if set to True.\n",
      " |\n",
      " |          .. versionchanged:: 2.0.0\n",
      " |              The default value of ``numeric_only`` is now ``False``.\n",
      " |\n",
      " |      na_option : {'keep', 'top', 'bottom'}, default 'keep'\n",
      " |          How to rank NaN values:\n",
      " |\n",
      " |          * keep: assign NaN rank to NaN values\n",
      " |          * top: assign lowest rank to NaN values\n",
      " |          * bottom: assign highest rank to NaN values\n",
      " |\n",
      " |      ascending : bool, default True\n",
      " |          Whether or not the elements should be ranked in ascending order.\n",
      " |      pct : bool, default False\n",
      " |          Whether or not to display the returned rankings in percentile\n",
      " |          form.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          Return a Series or DataFrame with data ranks as values.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.groupby.DataFrameGroupBy.rank : Rank of values within each group.\n",
      " |      core.groupby.SeriesGroupBy.rank : Rank of values within each group.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(data={'Animal': ['cat', 'penguin', 'dog',\n",
      " |      ...                                    'spider', 'snake'],\n",
      " |      ...                         'Number_legs': [4, 2, 4, 8, np.nan]})\n",
      " |      >>> df\n",
      " |          Animal  Number_legs\n",
      " |      0      cat          4.0\n",
      " |      1  penguin          2.0\n",
      " |      2      dog          4.0\n",
      " |      3   spider          8.0\n",
      " |      4    snake          NaN\n",
      " |\n",
      " |      Ties are assigned the mean of the ranks (by default) for the group.\n",
      " |\n",
      " |      >>> s = pd.Series(range(5), index=list(\"abcde\"))\n",
      " |      >>> s[\"d\"] = s[\"b\"]\n",
      " |      >>> s.rank()\n",
      " |      a    1.0\n",
      " |      b    2.5\n",
      " |      c    4.0\n",
      " |      d    2.5\n",
      " |      e    5.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      The following example shows how the method behaves with the above\n",
      " |      parameters:\n",
      " |\n",
      " |      * default_rank: this is the default behaviour obtained without using\n",
      " |        any parameter.\n",
      " |      * max_rank: setting ``method = 'max'`` the records that have the\n",
      " |        same values are ranked using the highest rank (e.g.: since 'cat'\n",
      " |        and 'dog' are both in the 2nd and 3rd position, rank 3 is assigned.)\n",
      " |      * NA_bottom: choosing ``na_option = 'bottom'``, if there are records\n",
      " |        with NaN values they are placed at the bottom of the ranking.\n",
      " |      * pct_rank: when setting ``pct = True``, the ranking is expressed as\n",
      " |        percentile rank.\n",
      " |\n",
      " |      >>> df['default_rank'] = df['Number_legs'].rank()\n",
      " |      >>> df['max_rank'] = df['Number_legs'].rank(method='max')\n",
      " |      >>> df['NA_bottom'] = df['Number_legs'].rank(na_option='bottom')\n",
      " |      >>> df['pct_rank'] = df['Number_legs'].rank(pct=True)\n",
      " |      >>> df\n",
      " |          Animal  Number_legs  default_rank  max_rank  NA_bottom  pct_rank\n",
      " |      0      cat          4.0           2.5       3.0        2.5     0.625\n",
      " |      1  penguin          2.0           1.0       1.0        1.0     0.250\n",
      " |      2      dog          4.0           2.5       3.0        2.5     0.625\n",
      " |      3   spider          8.0           4.0       4.0        4.0     1.000\n",
      " |      4    snake          NaN           NaN       NaN        5.0       NaN\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.rank <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.rank.html>`_ for more.\n",
      " |\n",
      " |  rename_axis(self, mapper=<no_default>, *, index=<no_default>, columns=<no_default>, axis=0, copy=None, inplace=False) -> 'DataFrame | Series | None'\n",
      " |      Set the name of the axis for the index or columns.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.rename_axis <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.rename_axis.html>`_, `pandas.Series.rename_axis <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.rename_axis.html>`_ for more.\n",
      " |\n",
      " |  reorder_levels(self, order, axis=0) -> 'Self'\n",
      " |      Rearrange index levels using input order.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.reorder_levels <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.reorder_levels.html>`_, `pandas.Series.reorder_levels <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.reorder_levels.html>`_ for more.\n",
      " |\n",
      " |  resample(self, rule, axis: 'Axis' = <no_default>, closed: 'Optional[str]' = None, label: 'Optional[str]' = None, convention: 'str' = <no_default>, kind: 'Optional[str]' = <no_default>, on: 'Level' = None, level: 'Level' = None, origin: 'str | TimestampConvertibleTypes' = 'start_day', offset: 'Optional[TimedeltaConvertibleTypes]' = None, group_keys=False) -> 'Resampler'\n",
      " |      Resample time-series data.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.resample <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.resample.html>`_, `pandas.Series.resample <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.resample.html>`_ for more.\n",
      " |\n",
      " |  reset_index(self, level: 'IndexLabel' = None, *, drop: 'bool' = False, inplace: 'bool' = False, col_level: 'Hashable' = 0, col_fill: 'Hashable' = '', allow_duplicates=<no_default>, names: 'Hashable | Sequence[Hashable]' = None) -> 'DataFrame | Series | None'\n",
      " |      Reset the index, or a level of it.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.reset_index <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.reset_index.html>`_, `pandas.Series.reset_index <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.reset_index.html>`_ for more.\n",
      " |\n",
      " |  rolling(self, window, min_periods: 'int | None' = None, center: 'bool' = False, win_type: 'str | None' = None, on: 'str | None' = None, axis: 'Axis' = <no_default>, closed: 'str | None' = None, step: 'int | None' = None, method: 'str' = 'single') -> 'Rolling | Window'\n",
      " |      Provide rolling window calculations.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.rolling <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.rolling.html>`_, `pandas.Series.rolling <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.rolling.html>`_ for more.\n",
      " |\n",
      " |  round(self, decimals=0, *args, **kwargs) -> 'Self'\n",
      " |      Round a `BasePandasDataset` to a variable number of decimal places.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.round <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.round.html>`_, `pandas.Series.round <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.round.html>`_ for more.\n",
      " |\n",
      " |  sample(self, n: 'int | None' = None, frac: 'float | None' = None, replace: 'bool' = False, weights=None, random_state: 'RandomState | None' = None, axis: 'Axis | None' = None, ignore_index: 'bool' = False) -> 'Self'\n",
      " |      Return a random sample of items from an axis of object.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.sample <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.sample.html>`_, `pandas.Series.sample <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.sample.html>`_ for more.\n",
      " |\n",
      " |  sem(self, axis: 'Axis' = 0, skipna: 'bool' = True, ddof: 'int' = 1, numeric_only=False, **kwargs) -> 'Series | float'\n",
      " |      Return unbiased standard error of the mean over requested axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.sem <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.sem.html>`_, `pandas.Series.sem <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.sem.html>`_ for more.\n",
      " |\n",
      " |  set_axis(self, labels, *, axis: 'Axis' = 0, copy=None) -> 'Self'\n",
      " |      Assign desired index to given axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.set_axis <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.set_axis.html>`_, `pandas.Series.set_axis <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.set_axis.html>`_ for more.\n",
      " |\n",
      " |  set_flags(self, *, copy: 'bool' = False, allows_duplicate_labels: 'Optional[bool]' = None) -> 'Self'\n",
      " |      Return a new `BasePandasDataset` with updated flags.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.set_flags <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.set_flags.html>`_, `pandas.Series.set_flags <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.set_flags.html>`_ for more.\n",
      " |\n",
      " |  shift(self, periods: 'int' = 1, freq=None, axis: 'Axis' = 0, fill_value: 'Hashable' = <no_default>, suffix=None) -> 'Self | DataFrame'\n",
      " |      Shift index by desired number of periods with an optional time `freq`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.shift <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.shift.html>`_, `pandas.Series.shift <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.shift.html>`_ for more.\n",
      " |\n",
      " |  skew(self, axis: 'Axis' = 0, skipna: 'bool' = True, numeric_only=False, **kwargs) -> 'Series | float'\n",
      " |      Return unbiased skew over requested axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.skew <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.skew.html>`_, `pandas.Series.skew <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.skew.html>`_ for more.\n",
      " |\n",
      " |  sort_index(self, *, axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True, ignore_index: 'bool' = False, key: 'Optional[IndexKeyFunc]' = None) -> 'Self | None'\n",
      " |      Sort object by labels (along an axis).\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.sort_index <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.sort_index.html>`_, `pandas.Series.sort_index <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.sort_index.html>`_ for more.\n",
      " |\n",
      " |  sort_values(self, by, *, axis=0, ascending=True, inplace: 'bool' = False, kind='quicksort', na_position='last', ignore_index: 'bool' = False, key: 'Optional[IndexKeyFunc]' = None) -> 'Self | None'\n",
      " |      Sort by the values along either axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.sort_values <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.sort_values.html>`_, `pandas.Series.sort_values <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.sort_values.html>`_ for more.\n",
      " |\n",
      " |  std(self, axis: 'Axis' = 0, skipna: 'bool' = True, ddof: 'int' = 1, numeric_only=False, **kwargs) -> 'Series | float'\n",
      " |      Return sample standard deviation over requested axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.std <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.std.html>`_, `pandas.Series.std <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.std.html>`_ for more.\n",
      " |\n",
      " |  swapaxes(self, axis1, axis2, copy=None) -> 'Self'\n",
      " |      Interchange axes and swap values axes appropriately.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.swapaxes <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.swapaxes.html>`_, `pandas.Series.swapaxes <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.swapaxes.html>`_ for more.\n",
      " |\n",
      " |  swaplevel(self, i=-2, j=-1, axis=0) -> 'Self'\n",
      " |      Swap levels `i` and `j` in a `MultiIndex`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.swaplevel <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.swaplevel.html>`_, `pandas.Series.swaplevel <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.swaplevel.html>`_ for more.\n",
      " |\n",
      " |  tail(self, n=5) -> 'Self'\n",
      " |      Return the last `n` rows.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.tail <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.tail.html>`_, `pandas.Series.tail <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.tail.html>`_ for more.\n",
      " |\n",
      " |  take(self, indices, axis=0, **kwargs) -> 'Self'\n",
      " |      Return the elements in the given *positional* indices along an axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.take <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.take.html>`_, `pandas.Series.take <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.take.html>`_ for more.\n",
      " |\n",
      " |  to_clipboard(self, excel=True, sep=None, **kwargs)\n",
      " |      Copy object to the system clipboard.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_clipboard <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_clipboard.html>`_, `pandas.Series.to_clipboard <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.to_clipboard.html>`_ for more.\n",
      " |\n",
      " |  to_csv(self, path_or_buf=None, sep=',', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression='infer', quoting=None, quotechar='\"', lineterminator=None, chunksize=None, date_format=None, doublequote=True, escapechar=None, decimal='.', errors: 'str' = 'strict', storage_options: 'StorageOptions' = None) -> 'str | None'\n",
      " |      Write object to a comma-separated values (csv) file.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str, path object, file-like object, or None, default None\n",
      " |          String, path object (implementing os.PathLike[str]), or file-like\n",
      " |          object implementing a write() function. If None, the result is\n",
      " |          returned as a string. If a non-binary file object is passed, it should\n",
      " |          be opened with `newline=''`, disabling universal newlines. If a binary\n",
      " |          file object is passed, `mode` might need to contain a `'b'`.\n",
      " |      sep : str, default ','\n",
      " |          String of length 1. Field delimiter for the output file.\n",
      " |      na_rep : str, default ''\n",
      " |          Missing data representation.\n",
      " |      float_format : str, Callable, default None\n",
      " |          Format string for floating point numbers. If a Callable is given, it takes\n",
      " |          precedence over other numeric formatting parameters, like decimal.\n",
      " |      columns : sequence, optional\n",
      " |          Columns to write.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of strings is given it is\n",
      " |          assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      index_label : str or sequence, or False, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the object uses MultiIndex. If\n",
      " |          False do not print fields for index names. Use index_label=False\n",
      " |          for easier importing in R.\n",
      " |      mode : {'w', 'x', 'a'}, default 'w'\n",
      " |          Forwarded to either `open(mode=)` or `fsspec.open(mode=)` to control\n",
      " |          the file opening. Typical values include:\n",
      " |\n",
      " |          - 'w', truncate the file first.\n",
      " |          - 'x', exclusive creation, failing if the file already exists.\n",
      " |          - 'a', append to the end of file if it exists.\n",
      " |\n",
      " |      encoding : str, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'utf-8'. `encoding` is not supported if `path_or_buf`\n",
      " |          is a non-binary file object.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          For on-the-fly compression of the output data. If 'infer' and 'path_or_buf' is\n",
      " |          path-like, then detect compression from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      " |          (otherwise no compression).\n",
      " |          Set to ``None`` for no compression.\n",
      " |          Can also be a dict with key ``'method'`` set\n",
      " |          to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      " |          other key-value pairs are forwarded to\n",
      " |          ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      " |          ``bz2.BZ2File``, ``zstandard.ZstdCompressor``, ``lzma.LZMAFile`` or\n",
      " |          ``tarfile.TarFile``, respectively.\n",
      " |          As an example, the following could be passed for faster compression and to create\n",
      " |          a reproducible gzip archive:\n",
      " |          ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |              Added support for `.tar` files.\n",
      " |\n",
      " |             May be a dict with key 'method' as compression mode\n",
      " |             and other entries as additional compression options if\n",
      " |             compression mode is 'zip'.\n",
      " |\n",
      " |             Passing compression options as keys in dict is\n",
      " |             supported for compression modes 'gzip', 'bz2', 'zstd', and 'zip'.\n",
      " |      quoting : optional constant from csv module\n",
      " |          Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      " |          then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      " |          will treat them as non-numeric.\n",
      " |      quotechar : str, default '\\\"'\n",
      " |          String of length 1. Character used to quote fields.\n",
      " |      lineterminator : str, optional\n",
      " |          The newline character or character sequence to use in the output\n",
      " |          file. Defaults to `os.linesep`, which depends on the OS in which\n",
      " |          this method is called ('\\\\n' for linux, '\\\\r\\\\n' for Windows, i.e.).\n",
      " |\n",
      " |          .. versionchanged:: 1.5.0\n",
      " |\n",
      " |              Previously was line_terminator, changed for consistency with\n",
      " |              read_csv and the standard library 'csv' module.\n",
      " |\n",
      " |      chunksize : int or None\n",
      " |          Rows to write at a time.\n",
      " |      date_format : str, default None\n",
      " |          Format string for datetime objects.\n",
      " |      doublequote : bool, default True\n",
      " |          Control quoting of `quotechar` inside a field.\n",
      " |      escapechar : str, default None\n",
      " |          String of length 1. Character used to escape `sep` and `quotechar`\n",
      " |          when appropriate.\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator. E.g. use ',' for\n",
      " |          European data.\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |\n",
      " |      storage_options : dict, optional\n",
      " |          Extra options that make sense for a particular storage connection, e.g.\n",
      " |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      " |          are forwarded to ``urllib.request.Request`` as header options. For other\n",
      " |          URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      " |          forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      " |          details, and for more examples on storage options refer `here\n",
      " |          <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      " |          highlight=storage_options#reading-writing-remote-files>`_.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If path_or_buf is None, returns the resulting csv format as a\n",
      " |          string. Otherwise returns None.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_csv : Load a CSV file into a DataFrame.\n",
      " |      to_excel : Write DataFrame to an Excel file.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create 'out.csv' containing 'df' without indices\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
      " |      ...                    'mask': ['red', 'purple'],\n",
      " |      ...                    'weapon': ['sai', 'bo staff']})\n",
      " |      >>> df.to_csv('out.csv', index=False)  # doctest: +SKIP\n",
      " |\n",
      " |      Create 'out.zip' containing 'out.csv'\n",
      " |\n",
      " |      >>> df.to_csv(index=False)\n",
      " |      'name,mask,weapon\\nRaphael,red,sai\\nDonatello,purple,bo staff\\n'\n",
      " |      >>> compression_opts = dict(method='zip',\n",
      " |      ...                         archive_name='out.csv')  # doctest: +SKIP\n",
      " |      >>> df.to_csv('out.zip', index=False,\n",
      " |      ...           compression=compression_opts)  # doctest: +SKIP\n",
      " |\n",
      " |      To write a csv file to a new folder or nested folder you will first\n",
      " |      need to create it using either Pathlib or os:\n",
      " |\n",
      " |      >>> from pathlib import Path  # doctest: +SKIP\n",
      " |      >>> filepath = Path('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      " |      >>> filepath.parent.mkdir(parents=True, exist_ok=True)  # doctest: +SKIP\n",
      " |      >>> df.to_csv(filepath)  # doctest: +SKIP\n",
      " |\n",
      " |      >>> import os  # doctest: +SKIP\n",
      " |      >>> os.makedirs('folder/subfolder', exist_ok=True)  # doctest: +SKIP\n",
      " |      >>> df.to_csv('folder/subfolder/out.csv')  # doctest: +SKIP\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_csv <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_csv.html>`_, `pandas.Series.to_csv <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.to_csv.html>`_ for more.\n",
      " |\n",
      " |  to_dict(self, orient='dict', into=<class 'dict'>, index=True) -> 'dict'\n",
      " |      Convert the DataFrame to a dictionary.\n",
      " |\n",
      " |      The type of the key-value pairs can be customized with the parameters\n",
      " |      (see below).\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      orient : str {'dict', 'list', 'series', 'split', 'tight', 'records', 'index'}\n",
      " |          Determines the type of the values of the dictionary.\n",
      " |\n",
      " |          - 'dict' (default) : dict like {column -> {index -> value}}\n",
      " |          - 'list' : dict like {column -> [values]}\n",
      " |          - 'series' : dict like {column -> Series(values)}\n",
      " |          - 'split' : dict like\n",
      " |            {'index' -> [index], 'columns' -> [columns], 'data' -> [values]}\n",
      " |          - 'tight' : dict like\n",
      " |            {'index' -> [index], 'columns' -> [columns], 'data' -> [values],\n",
      " |            'index_names' -> [index.names], 'column_names' -> [column.names]}\n",
      " |          - 'records' : list like\n",
      " |            [{column -> value}, ... , {column -> value}]\n",
      " |          - 'index' : dict like {index -> {column -> value}}\n",
      " |\n",
      " |          .. versionadded:: 1.4.0\n",
      " |              'tight' as an allowed value for the ``orient`` argument\n",
      " |\n",
      " |      into : class, default dict\n",
      " |          The collections.abc.MutableMapping subclass used for all Mappings\n",
      " |          in the return value.  Can be the actual class or an empty\n",
      " |          instance of the mapping type you want.  If you want a\n",
      " |          collections.defaultdict, you must pass it initialized.\n",
      " |\n",
      " |      index : bool, default True\n",
      " |          Whether to include the index item (and index_names item if `orient`\n",
      " |          is 'tight') in the returned dictionary. Can only be ``False``\n",
      " |          when `orient` is 'split' or 'tight'.\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict, list or collections.abc.MutableMapping\n",
      " |          Return a collections.abc.MutableMapping object representing the\n",
      " |          DataFrame. The resulting transformation depends on the `orient`\n",
      " |          parameter.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.from_dict: Create a DataFrame from a dictionary.\n",
      " |      DataFrame.to_json: Convert a DataFrame to JSON format.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'col1': [1, 2],\n",
      " |      ...                    'col2': [0.5, 0.75]},\n",
      " |      ...                   index=['row1', 'row2'])\n",
      " |      >>> df\n",
      " |            col1  col2\n",
      " |      row1     1  0.50\n",
      " |      row2     2  0.75\n",
      " |      >>> df.to_dict()\n",
      " |      {'col1': {'row1': 1, 'row2': 2}, 'col2': {'row1': 0.5, 'row2': 0.75}}\n",
      " |\n",
      " |      You can specify the return orientation.\n",
      " |\n",
      " |      >>> df.to_dict('series')\n",
      " |      {'col1': row1    1\n",
      " |               row2    2\n",
      " |      Name: col1, dtype: int64,\n",
      " |      'col2': row1    0.50\n",
      " |              row2    0.75\n",
      " |      Name: col2, dtype: float64}\n",
      " |\n",
      " |      >>> df.to_dict('split')\n",
      " |      {'index': ['row1', 'row2'], 'columns': ['col1', 'col2'],\n",
      " |       'data': [[1, 0.5], [2, 0.75]]}\n",
      " |\n",
      " |      >>> df.to_dict('records')\n",
      " |      [{'col1': 1, 'col2': 0.5}, {'col1': 2, 'col2': 0.75}]\n",
      " |\n",
      " |      >>> df.to_dict('index')\n",
      " |      {'row1': {'col1': 1, 'col2': 0.5}, 'row2': {'col1': 2, 'col2': 0.75}}\n",
      " |\n",
      " |      >>> df.to_dict('tight')\n",
      " |      {'index': ['row1', 'row2'], 'columns': ['col1', 'col2'],\n",
      " |       'data': [[1, 0.5], [2, 0.75]], 'index_names': [None], 'column_names': [None]}\n",
      " |\n",
      " |      You can also specify the mapping type.\n",
      " |\n",
      " |      >>> from collections import OrderedDict, defaultdict\n",
      " |      >>> df.to_dict(into=OrderedDict)\n",
      " |      OrderedDict([('col1', OrderedDict([('row1', 1), ('row2', 2)])),\n",
      " |                   ('col2', OrderedDict([('row1', 0.5), ('row2', 0.75)]))])\n",
      " |\n",
      " |      If you want a `defaultdict`, you need to initialize it:\n",
      " |\n",
      " |      >>> dd = defaultdict(list)\n",
      " |      >>> df.to_dict('records', into=dd)\n",
      " |      [defaultdict(<class 'list'>, {'col1': 1, 'col2': 0.5}),\n",
      " |       defaultdict(<class 'list'>, {'col1': 2, 'col2': 0.75})]\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_dict <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_dict.html>`_, `pandas.Series.to_dict <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.to_dict.html>`_ for more.\n",
      " |\n",
      " |  to_excel(self, excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, inf_rep='inf', freeze_panes=None, storage_options: 'StorageOptions' = None, engine_kwargs=None) -> 'None'\n",
      " |      Write object to an Excel sheet.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_excel <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_excel.html>`_, `pandas.Series.to_excel <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.to_excel.html>`_ for more.\n",
      " |\n",
      " |  to_hdf(self, path_or_buf, key: 'str', mode: \"Literal['a', 'w', 'r+']\" = 'a', complevel: 'int | None' = None, complib: \"Literal['zlib', 'lzo', 'bzip2', 'blosc'] | None\" = None, append: 'bool' = False, format: \"Literal['fixed', 'table'] | None\" = None, index: 'bool' = True, min_itemsize: 'int | dict[str, int] | None' = None, nan_rep=None, dropna: 'bool | None' = None, data_columns: 'Literal[True] | list[str] | None' = None, errors: 'str' = 'strict', encoding: 'str' = 'UTF-8') -> 'None'\n",
      " |      Write the contained data to an HDF5 file using HDFStore.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_hdf <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_hdf.html>`_, `pandas.Series.to_hdf <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.to_hdf.html>`_ for more.\n",
      " |\n",
      " |  to_json(self, path_or_buf=None, orient=None, date_format=None, double_precision=10, force_ascii=True, date_unit='ms', default_handler=None, lines=False, compression='infer', index=None, indent=None, storage_options: 'StorageOptions' = None, mode='w') -> 'str | None'\n",
      " |      Convert the object to a JSON string.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_json <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_json.html>`_, `pandas.Series.to_json <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.to_json.html>`_ for more.\n",
      " |\n",
      " |  to_latex(self, buf=None, columns=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None, caption=None, label=None, position=None) -> 'str | None'\n",
      " |      Render object to a LaTeX tabular, longtable, or nested table.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_latex <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_latex.html>`_, `pandas.Series.to_latex <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.to_latex.html>`_ for more.\n",
      " |\n",
      " |  to_markdown(self, buf=None, mode: 'str' = 'wt', index: 'bool' = True, storage_options: 'StorageOptions' = None, **kwargs) -> 'str'\n",
      " |      Print `BasePandasDataset` in Markdown-friendly format.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_markdown <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_markdown.html>`_, `pandas.Series.to_markdown <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.to_markdown.html>`_ for more.\n",
      " |\n",
      " |  to_numpy(self, dtype=None, copy=False, na_value=<no_default>) -> 'np.ndarray'\n",
      " |      Convert the `BasePandasDataset` to a NumPy array or a Modin wrapper for NumPy array.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_numpy <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_numpy.html>`_, `pandas.Series.to_numpy <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.to_numpy.html>`_ for more.\n",
      " |\n",
      " |  to_pickle(self, path, compression: 'CompressionOptions' = 'infer', protocol: 'int' = 5, storage_options: 'StorageOptions' = None) -> 'None'\n",
      " |      Pickle (serialize) object to file.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_pickle <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_pickle.html>`_, `pandas.Series.to_pickle <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.to_pickle.html>`_ for more.\n",
      " |\n",
      " |  to_sql(self, name, con, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None, method=None) -> 'int | None'\n",
      " |      Write records stored in a `BasePandasDataset` to a SQL database.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_sql <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_sql.html>`_, `pandas.Series.to_sql <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.to_sql.html>`_ for more.\n",
      " |\n",
      " |  to_string(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, max_rows=None, min_rows=None, max_cols=None, show_dimensions=False, decimal='.', line_width=None, max_colwidth=None, encoding=None) -> 'str | None'\n",
      " |      Render a `BasePandasDataset` to a console-friendly tabular output.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_string <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_string.html>`_, `pandas.Series.to_string <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.to_string.html>`_ for more.\n",
      " |\n",
      " |  to_xarray(self)\n",
      " |      Return an xarray object from the `BasePandasDataset`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.to_xarray <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.to_xarray.html>`_, `pandas.Series.to_xarray <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.to_xarray.html>`_ for more.\n",
      " |\n",
      " |  transform(self, func, axis=0, *args, **kwargs) -> 'Self'\n",
      " |      Call ``func`` on self producing a `BasePandasDataset` with the same axis shape as self.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.transform <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.transform.html>`_, `pandas.Series.transform <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.transform.html>`_ for more.\n",
      " |\n",
      " |  truncate(self, before=None, after=None, axis=None, copy=None) -> 'Self'\n",
      " |      Truncate a `BasePandasDataset` before and after some index value.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.truncate <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.truncate.html>`_, `pandas.Series.truncate <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.truncate.html>`_ for more.\n",
      " |\n",
      " |  tz_convert(self, tz, axis=0, level=None, copy=None) -> 'Self'\n",
      " |      Convert tz-aware axis to target time zone.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.tz_convert <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.tz_convert.html>`_, `pandas.Series.tz_convert <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.tz_convert.html>`_ for more.\n",
      " |\n",
      " |  tz_localize(self, tz, axis=0, level=None, copy=None, ambiguous='raise', nonexistent='raise') -> 'Self'\n",
      " |      Localize tz-naive index of a `BasePandasDataset` to target time zone.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.tz_localize <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.tz_localize.html>`_, `pandas.Series.tz_localize <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.tz_localize.html>`_ for more.\n",
      " |\n",
      " |  value_counts(self, subset: 'Sequence[Hashable] | None' = None, normalize: 'bool' = False, sort: 'bool' = True, ascending: 'bool' = False, dropna: 'bool' = True) -> 'Series'\n",
      " |      Return a Series containing the frequency of each distinct row in the Dataframe.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : label or list of labels, optional\n",
      " |          Columns to use when counting unique combinations.\n",
      " |      normalize : bool, default False\n",
      " |          Return proportions rather than frequencies.\n",
      " |      sort : bool, default True\n",
      " |          Sort by frequencies when True. Sort by DataFrame column values when False.\n",
      " |      ascending : bool, default False\n",
      " |          Sort in ascending order.\n",
      " |      dropna : bool, default True\n",
      " |          Don't include counts of rows that contain NA values.\n",
      " |\n",
      " |          .. versionadded:: 1.3.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.value_counts: Equivalent method on Series.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.value_counts <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.value_counts.html>`_ for more.\n",
      " |      The returned Series will have a MultiIndex with one level per input\n",
      " |      column but an Index (non-multi) for a single label. By default, rows\n",
      " |      that contain any NA values are omitted from the result. By default,\n",
      " |      the resulting Series will be in descending order so that the first\n",
      " |      element is the most frequently-occurring row.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4, 4, 6],\n",
      " |      ...                    'num_wings': [2, 0, 0, 0]},\n",
      " |      ...                   index=['falcon', 'dog', 'cat', 'ant'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings\n",
      " |      falcon         2          2\n",
      " |      dog            4          0\n",
      " |      cat            4          0\n",
      " |      ant            6          0\n",
      " |\n",
      " |      >>> df.value_counts()\n",
      " |      num_legs  num_wings\n",
      " |      4         0            2\n",
      " |      2         2            1\n",
      " |      6         0            1\n",
      " |      Name: count, dtype: int64\n",
      " |\n",
      " |      >>> df.value_counts(sort=False)\n",
      " |      num_legs  num_wings\n",
      " |      2         2            1\n",
      " |      4         0            2\n",
      " |      6         0            1\n",
      " |      Name: count, dtype: int64\n",
      " |\n",
      " |      >>> df.value_counts(ascending=True)\n",
      " |      num_legs  num_wings\n",
      " |      2         2            1\n",
      " |      6         0            1\n",
      " |      4         0            2\n",
      " |      Name: count, dtype: int64\n",
      " |\n",
      " |      >>> df.value_counts(normalize=True)\n",
      " |      num_legs  num_wings\n",
      " |      4         0            0.50\n",
      " |      2         2            0.25\n",
      " |      6         0            0.25\n",
      " |      Name: proportion, dtype: float64\n",
      " |\n",
      " |      With `dropna` set to `False` we can also count rows with NA values.\n",
      " |\n",
      " |      >>> df = pd.DataFrame({'first_name': ['John', 'Anne', 'John', 'Beth'],\n",
      " |      ...                    'middle_name': ['Smith', pd.NA, pd.NA, 'Louise']})\n",
      " |      >>> df\n",
      " |        first_name middle_name\n",
      " |      0       John       Smith\n",
      " |      1       Anne        <NA>\n",
      " |      2       John        <NA>\n",
      " |      3       Beth      Louise\n",
      " |\n",
      " |      >>> df.value_counts()\n",
      " |      first_name  middle_name\n",
      " |      Beth        Louise         1\n",
      " |      John        Smith          1\n",
      " |      Name: count, dtype: int64\n",
      " |\n",
      " |      >>> df.value_counts(dropna=False)\n",
      " |      first_name  middle_name\n",
      " |      Anne        NaN            1\n",
      " |      Beth        Louise         1\n",
      " |      John        Smith          1\n",
      " |                  NaN            1\n",
      " |      Name: count, dtype: int64\n",
      " |\n",
      " |      >>> df.value_counts(\"first_name\")\n",
      " |      first_name\n",
      " |      John    2\n",
      " |      Anne    1\n",
      " |      Beth    1\n",
      " |      Name: count, dtype: int64\n",
      " |\n",
      " |  var(self, axis: 'Axis' = 0, skipna: 'bool' = True, ddof: 'int' = 1, numeric_only=False, **kwargs) -> 'Series | float'\n",
      " |      Return unbiased variance over requested axis.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.var <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.var.html>`_, `pandas.Series.var <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.var.html>`_ for more.\n",
      " |\n",
      " |  xs(self, key, axis=0, level=None, drop_level: 'bool' = True) -> 'Self'\n",
      " |      Return cross-section from the Series/DataFrame.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.xs <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.xs.html>`_, `pandas.Series.xs <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.xs.html>`_ for more.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from modin.pandas.base.BasePandasDataset:\n",
      " |\n",
      " |  at\n",
      " |      Get a single value for a row/column label pair.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.at <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.at.html>`_, `pandas.Series.at <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.at.html>`_ for more.\n",
      " |\n",
      " |  flags\n",
      " |      Get the properties associated with this pandas object.\n",
      " |\n",
      " |      The available flags are\n",
      " |\n",
      " |      * :attr:`Flags.allows_duplicate_labels`\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Flags : Flags that apply to pandas objects.\n",
      " |      DataFrame.attrs : Global metadata applying to this dataset.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.flags <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.flags.html>`_, `pandas.Series.flags <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.flags.html>`_ for more.\n",
      " |      \"Flags\" differ from \"metadata\". Flags reflect properties of the\n",
      " |      pandas object (the Series or DataFrame). Metadata refer to properties\n",
      " |      of the dataset, and should be stored in :attr:`DataFrame.attrs`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2]})\n",
      " |      >>> df.flags\n",
      " |      <Flags(allows_duplicate_labels=True)>\n",
      " |\n",
      " |      Flags can be get or set using ``.``\n",
      " |\n",
      " |      >>> df.flags.allows_duplicate_labels\n",
      " |      True\n",
      " |      >>> df.flags.allows_duplicate_labels = False\n",
      " |\n",
      " |      Or by slicing with a key\n",
      " |\n",
      " |      >>> df.flags[\"allows_duplicate_labels\"]\n",
      " |      False\n",
      " |      >>> df.flags[\"allows_duplicate_labels\"] = True\n",
      " |\n",
      " |  iat\n",
      " |      Get a single value for a row/column pair by integer position.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.iat <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.iat.html>`_, `pandas.Series.iat <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.iat.html>`_ for more.\n",
      " |\n",
      " |  iloc\n",
      " |      Purely integer-location based indexing for selection by position.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.iloc <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.iloc.html>`_, `pandas.Series.iloc <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.iloc.html>`_ for more.\n",
      " |\n",
      " |  loc\n",
      " |      Get a group of rows and columns by label(s) or a boolean array.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.loc <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.loc.html>`_, `pandas.Series.loc <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.loc.html>`_ for more.\n",
      " |\n",
      " |  size\n",
      " |      Return an int representing the number of elements in this `BasePandasDataset` object.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.size <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.size.html>`_, `pandas.Series.size <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.size.html>`_ for more.\n",
      " |\n",
      " |  values\n",
      " |      Return a NumPy representation of the `BasePandasDataset`.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      See pandas API documentation for `pandas.DataFrame.values <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.DataFrame.values.html>`_, `pandas.Series.values <https://pandas.pydata.org/pandas-docs/version/2.2.3/reference/api/pandas.Series.values.html>`_ for more.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from modin.pandas.base.BasePandasDataset:\n",
      " |\n",
      " |  index\n",
      " |      Get the index for this DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Index\n",
      " |          The union of all indexes across the partitions.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from modin.pandas.base.BasePandasDataset:\n",
      " |\n",
      " |  __hash__ = None\n",
      " |\n",
      " |  modin = <class 'modin.pandas.accessor.ModinAPI'>\n",
      " |      Namespace class for accessing additional Modin functions that are not available in pandas.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame or Series\n",
      " |          Object to operate on.\n",
      " |\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from modin.logging.class_logger.ClassLogger:\n",
      " |\n",
      " |  __init_subclass__(modin_layer: Optional[str] = None, class_name: Optional[str] = None, log_level: Optional[modin.logging.config.LogLevel] = None, **kwargs: Dict) -> None\n",
      " |      Apply logging decorator to all children of ``ClassLogger``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      modin_layer : str, optional\n",
      " |          Specified by the logger (e.g. PANDAS-API).\n",
      " |      class_name : str, optional\n",
      " |          The name of the class the decorator is being applied to.\n",
      " |          Composed from the decorated class name if not specified.\n",
      " |      log_level : LogLevel, optional\n",
      " |          The log level (LogLevel.INFO, LogLevel.DEBUG, LogLevel.WARNING, etc.).\n",
      " |      **kwargs : dict\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from modin.logging.class_logger.ClassLogger:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fd13d56-9137-4eb5-bdad-5a14e61439c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 10:06:59,007\tINFO sql_datasource.py:145 -- Sharding is not supported. Falling back to reading all data in a single task.\n",
      "2025-05-05 10:06:59,015\tINFO sql_datasource.py:145 -- Sharding is not supported. Falling back to reading all data in a single task.\n",
      "2025-05-05 10:06:59,023\tINFO sql_datasource.py:145 -- Sharding is not supported. Falling back to reading all data in a single task.\n",
      "2025-05-05 10:06:59,030\tINFO sql_datasource.py:145 -- Sharding is not supported. Falling back to reading all data in a single task.\n",
      "2025-05-05 10:06:59,037\tINFO sql_datasource.py:145 -- Sharding is not supported. Falling back to reading all data in a single task.\n",
      "2025-05-05 10:06:59,045\tINFO sql_datasource.py:145 -- Sharding is not supported. Falling back to reading all data in a single task.\n",
      "2025-05-05 10:06:59,052\tINFO sql_datasource.py:145 -- Sharding is not supported. Falling back to reading all data in a single task.\n"
     ]
    }
   ],
   "source": [
    "def create_old_conn():\n",
    "    return sqlite3.connect(old_lrcat)\n",
    "\n",
    "images = ray.data.read_sql(\"SELECT * from Adobe_images\", create_old_conn)\n",
    "library_file = ray.data.read_sql(\"SELECT * from AgLibraryFile\", create_old_conn)\n",
    "library_folder = ray.data.read_sql(\"SELECT * from AgLibraryFolder\", create_old_conn)\n",
    "library_root_folder = ray.data.read_sql(\"SELECT * from AgLibraryRootFolder\", create_old_conn)\n",
    "harvested_exifdata = ray.data.read_sql(\"SELECT * from AgHarvestedExifMetaData\", create_old_conn)\n",
    "exif_camera_model =ray.data.read_sql(\"SELECT * from AgInternedExifCameraModel\", create_old_conn)\n",
    "exif_lens =ray.data.read_sql(\"SELECT * from AgInternedExifLens\", create_old_conn)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
